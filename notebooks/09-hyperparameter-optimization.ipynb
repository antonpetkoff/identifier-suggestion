{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from scipy.stats import uniform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [32, 64, 128, 256, 512, 1024],\n",
       " 'learning_rate': <scipy.stats._distn_infrastructure.rv_frozen at 0x7f2ef5770908>,\n",
       " 'dropout_rate': <scipy.stats._distn_infrastructure.rv_frozen at 0x7f2ef5770e80>,\n",
       " 'latent_dim': [256, 384, 512, 640, 768, 896, 1024],\n",
       " 'embedding_dim': [32, 48, 64, 80, 96, 112, 128],\n",
       " 'vocabulary_size': [2000, 3000, 4000, 5000, 6000, 7000],\n",
       " 'max_input_seq_length': [50, 75, 100, 125, 150, 175],\n",
       " 'max_output_seq_length': [5, 6, 7, 8]}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameter_grid = {\n",
    "#     'epochs': [25, 50, 100, 200], # it doesn't make sense to search epochs, when we can use early stopping\n",
    "    'batch_size': [2 ** n for n in range(5, 10 + 1)],\n",
    "    'learning_rate': uniform(loc=2, scale=4 - 2), # N ~ uniform in the inverval [2; 4], then the learning rate will be 10 ^ (-N)\n",
    "    'dropout_rate': uniform(loc=0.0, scale=0.2), # N ~ uniform in the interval [0.0; 0.2]\n",
    "    'latent_dim': list(range(256, 1024 + 1, 128)),\n",
    "    'embedding_dim': list(range(32, 128 + 1, 16)),\n",
    "    'vocabulary_size': list(range(2000, 7000 + 1, 1000)),\n",
    "    'max_input_seq_length': list(range(50, 200, 25)),\n",
    "    'max_output_seq_length': list(range(5, 8 + 1)),\n",
    "}\n",
    "parameter_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_float_values(obj):\n",
    "    return {\n",
    "        key: round(value, 6) if isinstance(value, float) else value\n",
    "        for key, value in obj.items()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exponentiate_learning_rate(params):\n",
    "    return {\n",
    "        **params,\n",
    "        'learning_rate': 10 ** -params['learning_rate']\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiments = {\n",
    "    f'experiment_{i}': round_float_values(exponentiate_learning_rate(params))\n",
    "    for i, params in enumerate(ParameterSampler(\n",
    "        parameter_grid,\n",
    "        n_iter=20,\n",
    "        random_state=0,\n",
    "    ))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"experiment_0\": {\n",
      "    \"batch_size\": 512,\n",
      "    \"dropout_rate\": 0.118569,\n",
      "    \"embedding_dim\": 32,\n",
      "    \"latent_dim\": 640,\n",
      "    \"learning_rate\": 0.000192,\n",
      "    \"max_input_seq_length\": 75,\n",
      "    \"max_output_seq_length\": 8,\n",
      "    \"vocabulary_size\": 7000\n",
      "  },\n",
      "  \"experiment_1\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"dropout_rate\": 0.087517,\n",
      "    \"embedding_dim\": 128,\n",
      "    \"latent_dim\": 256,\n",
      "    \"learning_rate\": 0.000118,\n",
      "    \"max_input_seq_length\": 100,\n",
      "    \"max_output_seq_length\": 6,\n",
      "    \"vocabulary_size\": 2000\n",
      "  },\n",
      "  \"experiment_2\": {\n",
      "    \"batch_size\": 64,\n",
      "    \"dropout_rate\": 0.185119,\n",
      "    \"embedding_dim\": 112,\n",
      "    \"latent_dim\": 256,\n",
      "    \"learning_rate\": 0.006695,\n",
      "    \"max_input_seq_length\": 125,\n",
      "    \"max_output_seq_length\": 5,\n",
      "    \"vocabulary_size\": 5000\n",
      "  },\n",
      "  \"experiment_3\": {\n",
      "    \"batch_size\": 1024,\n",
      "    \"dropout_rate\": 0.155631,\n",
      "    \"embedding_dim\": 32,\n",
      "    \"latent_dim\": 512,\n",
      "    \"learning_rate\": 0.001129,\n",
      "    \"max_input_seq_length\": 75,\n",
      "    \"max_output_seq_length\": 8,\n",
      "    \"vocabulary_size\": 7000\n",
      "  },\n",
      "  \"experiment_4\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"dropout_rate\": 0.135776,\n",
      "    \"embedding_dim\": 32,\n",
      "    \"latent_dim\": 384,\n",
      "    \"learning_rate\": 0.005168,\n",
      "    \"max_input_seq_length\": 50,\n",
      "    \"max_output_seq_length\": 8,\n",
      "    \"vocabulary_size\": 4000\n",
      "  },\n",
      "  \"experiment_5\": {\n",
      "    \"batch_size\": 512,\n",
      "    \"dropout_rate\": 0.09472,\n",
      "    \"embedding_dim\": 128,\n",
      "    \"latent_dim\": 640,\n",
      "    \"learning_rate\": 0.000336,\n",
      "    \"max_input_seq_length\": 150,\n",
      "    \"max_output_seq_length\": 7,\n",
      "    \"vocabulary_size\": 2000\n",
      "  },\n",
      "  \"experiment_6\": {\n",
      "    \"batch_size\": 32,\n",
      "    \"dropout_rate\": 0.064828,\n",
      "    \"embedding_dim\": 112,\n",
      "    \"latent_dim\": 1024,\n",
      "    \"learning_rate\": 0.003592,\n",
      "    \"max_input_seq_length\": 75,\n",
      "    \"max_output_seq_length\": 8,\n",
      "    \"vocabulary_size\": 6000\n",
      "  },\n",
      "  \"experiment_7\": {\n",
      "    \"batch_size\": 64,\n",
      "    \"dropout_rate\": 0.08999,\n",
      "    \"embedding_dim\": 32,\n",
      "    \"latent_dim\": 384,\n",
      "    \"learning_rate\": 0.000402,\n",
      "    \"max_input_seq_length\": 75,\n",
      "    \"max_output_seq_length\": 6,\n",
      "    \"vocabulary_size\": 5000\n",
      "  },\n",
      "  \"experiment_8\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"dropout_rate\": 0.042077,\n",
      "    \"embedding_dim\": 80,\n",
      "    \"latent_dim\": 256,\n",
      "    \"learning_rate\": 0.00234,\n",
      "    \"max_input_seq_length\": 175,\n",
      "    \"max_output_seq_length\": 5,\n",
      "    \"vocabulary_size\": 3000\n",
      "  },\n",
      "  \"experiment_9\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"dropout_rate\": 0.08772,\n",
      "    \"embedding_dim\": 96,\n",
      "    \"latent_dim\": 1024,\n",
      "    \"learning_rate\": 0.00625,\n",
      "    \"max_input_seq_length\": 150,\n",
      "    \"max_output_seq_length\": 8,\n",
      "    \"vocabulary_size\": 6000\n",
      "  },\n",
      "  \"experiment_10\": {\n",
      "    \"batch_size\": 512,\n",
      "    \"dropout_rate\": 0.11637,\n",
      "    \"embedding_dim\": 128,\n",
      "    \"latent_dim\": 768,\n",
      "    \"learning_rate\": 0.003245,\n",
      "    \"max_input_seq_length\": 175,\n",
      "    \"max_output_seq_length\": 6,\n",
      "    \"vocabulary_size\": 7000\n",
      "  },\n",
      "  \"experiment_11\": {\n",
      "    \"batch_size\": 32,\n",
      "    \"dropout_rate\": 0.027637,\n",
      "    \"embedding_dim\": 48,\n",
      "    \"latent_dim\": 640,\n",
      "    \"learning_rate\": 0.00183,\n",
      "    \"max_input_seq_length\": 175,\n",
      "    \"max_output_seq_length\": 7,\n",
      "    \"vocabulary_size\": 2000\n",
      "  },\n",
      "  \"experiment_12\": {\n",
      "    \"batch_size\": 64,\n",
      "    \"dropout_rate\": 0.167589,\n",
      "    \"embedding_dim\": 64,\n",
      "    \"latent_dim\": 256,\n",
      "    \"learning_rate\": 0.000111,\n",
      "    \"max_input_seq_length\": 100,\n",
      "    \"max_output_seq_length\": 7,\n",
      "    \"vocabulary_size\": 7000\n",
      "  },\n",
      "  \"experiment_13\": {\n",
      "    \"batch_size\": 32,\n",
      "    \"dropout_rate\": 0.120969,\n",
      "    \"embedding_dim\": 48,\n",
      "    \"latent_dim\": 256,\n",
      "    \"learning_rate\": 0.001308,\n",
      "    \"max_input_seq_length\": 125,\n",
      "    \"max_output_seq_length\": 7,\n",
      "    \"vocabulary_size\": 5000\n",
      "  },\n",
      "  \"experiment_14\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"dropout_rate\": 0.137732,\n",
      "    \"embedding_dim\": 128,\n",
      "    \"latent_dim\": 640,\n",
      "    \"learning_rate\": 0.000146,\n",
      "    \"max_input_seq_length\": 125,\n",
      "    \"max_output_seq_length\": 7,\n",
      "    \"vocabulary_size\": 5000\n",
      "  },\n",
      "  \"experiment_15\": {\n",
      "    \"batch_size\": 512,\n",
      "    \"dropout_rate\": 0.053078,\n",
      "    \"embedding_dim\": 80,\n",
      "    \"latent_dim\": 1024,\n",
      "    \"learning_rate\": 0.006488,\n",
      "    \"max_input_seq_length\": 75,\n",
      "    \"max_output_seq_length\": 5,\n",
      "    \"vocabulary_size\": 4000\n",
      "  },\n",
      "  \"experiment_16\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"dropout_rate\": 0.001871,\n",
      "    \"embedding_dim\": 64,\n",
      "    \"latent_dim\": 640,\n",
      "    \"learning_rate\": 0.000508,\n",
      "    \"max_input_seq_length\": 50,\n",
      "    \"max_output_seq_length\": 7,\n",
      "    \"vocabulary_size\": 5000\n",
      "  },\n",
      "  \"experiment_17\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"dropout_rate\": 0.110564,\n",
      "    \"embedding_dim\": 96,\n",
      "    \"latent_dim\": 256,\n",
      "    \"learning_rate\": 0.001821,\n",
      "    \"max_input_seq_length\": 50,\n",
      "    \"max_output_seq_length\": 6,\n",
      "    \"vocabulary_size\": 4000\n",
      "  },\n",
      "  \"experiment_18\": {\n",
      "    \"batch_size\": 256,\n",
      "    \"dropout_rate\": 0.140747,\n",
      "    \"embedding_dim\": 80,\n",
      "    \"latent_dim\": 896,\n",
      "    \"learning_rate\": 0.00136,\n",
      "    \"max_input_seq_length\": 50,\n",
      "    \"max_output_seq_length\": 8,\n",
      "    \"vocabulary_size\": 2000\n",
      "  },\n",
      "  \"experiment_19\": {\n",
      "    \"batch_size\": 128,\n",
      "    \"dropout_rate\": 0.11445,\n",
      "    \"embedding_dim\": 96,\n",
      "    \"latent_dim\": 640,\n",
      "    \"learning_rate\": 0.000124,\n",
      "    \"max_input_seq_length\": 50,\n",
      "    \"max_output_seq_length\": 5,\n",
      "    \"vocabulary_size\": 5000\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(json.dumps(experiments, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../experiments/random_search_1.json', 'w') as f:\n",
    "    json.dump(experiments, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
