{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "00-colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonpetkoff/identifier-suggestion/blob/master/notebooks/00-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJd9knlVGS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import utilities\n",
        "import os\n",
        "import shutil\n",
        "from subprocess import check_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntLDgQhocMeE",
        "colab_type": "code",
        "outputId": "aca2d4ce-2a29-4b61-b895-929c2d293331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May  6 07:24:32 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   71C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_PqX9NDdEJh",
        "colab_type": "code",
        "outputId": "6cd530f0-8dfd-408a-fe11-42354e9fd001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvcl4iohdWEi",
        "colab_type": "code",
        "outputId": "e3d3aadf-9c72-49f0-ad30-e5493327b613",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%env WORKSPACE_DIR=/content/gdrive/My Drive/src\n",
        "\n",
        "# TODO: how can one read an environment variable?!?\n",
        "%cd '/content/gdrive/My Drive/src'"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: WORKSPACE_DIR=/content/gdrive/My Drive/src\n",
            "/content/gdrive/My Drive/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNR4ZqljgeyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timestamp = check_output(['date', '-u', \"+%Y-%m-%dT%H-%M-%S\"]).decode('utf-8').strip()\n",
        "\n",
        "os.environ['PROJECT_DIR'] = os.path.join(\n",
        "    os.environ['WORKSPACE_DIR'],\n",
        "    f'identifier-suggestion-{timestamp}',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PoI39h1dEJ0",
        "colab_type": "code",
        "outputId": "178f26f8-c269-4977-9754-98a184bf79d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!git clone https://github.com/antonpetkoff/identifier-suggestion.git --depth 1 \"${PROJECT_DIR}\""
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/gdrive/My Drive/src/identifier-suggestion-2020-05-06T07-24-34'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 62 (delta 0), reused 38 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mki1yqMgixt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(os.environ['PROJECT_DIR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HjKIGx4i2dr",
        "colab_type": "code",
        "outputId": "4224cbb6-e5b4-4998-c83e-68f059aa6e07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!pwd\n",
        "!ls -l"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/src/identifier-suggestion-2020-05-06T07-24-34\n",
            "total 54\n",
            "-rw------- 1 root root 35149 May  6 07:24 LICENSE\n",
            "drwx------ 2 root root  4096 May  6 07:24 notebooks\n",
            "-rw------- 1 root root  6735 May  6 07:24 README.md\n",
            "drwx------ 2 root root  4096 May  6 07:24 requirements\n",
            "drwx------ 9 root root  4096 May  6 07:24 src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCr-lrn4SRhW",
        "colab_type": "code",
        "outputId": "704b5349-e910-4b21-e9bd-50e554d49fb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M7BkvE4dEJ-",
        "colab_type": "code",
        "outputId": "f50e5300-c484-4f47-96df-5f2a46910478",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        }
      },
      "source": [
        "# Google Colab has standard libraries like numpy, pandas, matplotlib and TF (of course) pre-installed\n",
        "!pip install -r requirements/colab.txt"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: javalang==0.13.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements/colab.txt (line 1)) (0.13.0)\n",
            "Requirement already satisfied: python-dotenv==0.13.0 in /usr/local/lib/python3.6/dist-packages (from -r requirements/colab.txt (line 2)) (0.13.0)\n",
            "Requirement already satisfied: wandb==0.8.35 in /usr/local/lib/python3.6/dist-packages (from -r requirements/colab.txt (line 3)) (0.8.35)\n",
            "Requirement already satisfied: tables==3.6.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements/colab.txt (line 4)) (3.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from javalang==0.13.0->-r requirements/colab.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: gql==0.2.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (0.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: sentry-sdk>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (0.14.3)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (0.4.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (5.4.8)\n",
            "Requirement already satisfied: subprocess32>=3.5.3 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.5.4)\n",
            "Requirement already satisfied: GitPython>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.1.2)\n",
            "Requirement already satisfied: watchdog>=0.8.3 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (0.10.2)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (7.1.2)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (7.352.0)\n",
            "Requirement already satisfied: shortuuid>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (1.0.1)\n",
            "Requirement already satisfied: configparser>=3.8.1 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (5.0.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables==3.6.1->-r requirements/colab.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables==3.6.1->-r requirements/colab.txt (line 4)) (2.7.1)\n",
            "Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.3)\n",
            "Requirement already satisfied: graphql-core<2,>=0.5.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (1.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.6/dist-packages (from GitPython>=1.0.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (4.0.5)\n",
            "Requirement already satisfied: pathtools>=0.1.1 in /usr/local/lib/python3.6/dist-packages (from watchdog>=0.8.3->wandb==0.8.35->-r requirements/colab.txt (line 3)) (0.1.2)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.9)\n",
            "Requirement already satisfied: smmap<4,>=3.0.1 in /usr/local/lib/python3.6/dist-packages (from gitdb<5,>=4.0.1->GitPython>=1.0.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASrqt3o4TP5E",
        "colab_type": "code",
        "outputId": "604a1204-ace0-4d64-8946-00778a616b58",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# provide secrets to the project, e.g. access to wandb\n",
        "shutil.copy(\n",
        "    os.path.join(os.environ['WORKSPACE_DIR'], 'secrets/.env'),\n",
        "    os.environ['PROJECT_DIR']\n",
        ")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/src/identifier-suggestion-2020-05-06T07-24-34/.env'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBhbZ4muuveC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# monkey-patch (mock) os.symlink to be a noop, because wandb.save() uses it, but it is not supported by Google Colab Notebooks\n",
        "os.symlink = lambda *x: print('Executing mocked noop symlink with arguments', x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY3fkLJIm7ja",
        "colab_type": "code",
        "outputId": "69471556-2ea6-4e64-e7dc-03ab62472289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from argparse import Namespace\n",
        "from src.pipelines.baseline import run\n",
        "\n",
        "params = {\n",
        "  'file_data_raw': '../data/interim/method-names-rich/elasticsearch.csv',\n",
        "  'file_model_dir': 'models/saved/baseline/',\n",
        "  'dir_preprocessed_data': '../data/interim/preprocessed/',\n",
        "  'max_input_length': 200,\n",
        "  'max_output_length': 8,\n",
        "  'input_vocab_size': 20000,\n",
        "  'input_embedding_dim': 128,\n",
        "  'output_vocab_size': 6000,\n",
        "  'output_embedding_dim': 128,\n",
        "  'latent_dim': 512,\n",
        "  'learning_rate': 0.0001,\n",
        "  'epochs': 10,\n",
        "  'batch_size': 512,\n",
        "  'random_seed': 1,\n",
        "}\n",
        "\n",
        "run(Namespace(**params))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment parameters:  Namespace(batch_size=512, dir_preprocessed_data='../data/interim/preprocessed/', epochs=10, file_data_raw='../data/interim/method-names-rich/elasticsearch.csv', file_model_dir='models/saved/baseline/', input_embedding_dim=128, input_vocab_size=20000, latent_dim=512, learning_rate=0.0001, max_input_length=200, max_output_length=8, output_embedding_dim=128, output_vocab_size=6000, random_seed=1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/antonpetkoff/identifier-suggestion\" target=\"_blank\">https://app.wandb.ai/antonpetkoff/identifier-suggestion</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/antonpetkoff/identifier-suggestion/runs/1jz7l1pn\" target=\"_blank\">https://app.wandb.ai/antonpetkoff/identifier-suggestion/runs/1jz7l1pn</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading preprocessed files...\n",
            "Loaded input vocabulary.\n",
            "Loaded output vocabulary.\n",
            "Loaded preprocessed files.\n",
            "epoch 1 - batch 10 - loss 3.87074613571167 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1049107164144516\n",
            "epoch 1 - batch 20 - loss 3.338876485824585 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.13918805122375488\n",
            "epoch 1 - batch 30 - loss 3.254514455795288 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16196057200431824\n",
            "epoch 1 - batch 40 - loss 2.5491278171539307 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16558314859867096\n",
            "epoch 1 - batch 50 - loss 2.2286159992218018 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1650223284959793\n",
            "epoch 1 - batch 60 - loss 2.2731873989105225 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16512741148471832\n",
            "epoch 1 - batch 70 - loss 2.1191537380218506 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1653180867433548\n",
            "epoch 1 - batch 80 - loss 2.530073881149292 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16572614014148712\n",
            "epoch 1 - batch 90 - loss 2.7664783000946045 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16499565541744232\n",
            "epoch 1 - batch 100 - loss 2.904240846633911 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1659347116947174\n",
            "epoch 1 - batch 110 - loss 2.9363210201263428 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16634030640125275\n",
            "epoch 1 - batch 120 - loss 2.7928483486175537 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1665620356798172\n",
            "epoch 1 - batch 130 - loss 3.212482213973999 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1671917885541916\n",
            "epoch 1 - batch 140 - loss 2.5607757568359375 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16729313135147095\n",
            "epoch 1 - batch 150 - loss 2.5673420429229736 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16776041686534882\n",
            "epoch 1 - batch 160 - loss 2.029757022857666 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16774378716945648\n",
            "epoch 1 - batch 170 - loss 2.0964252948760986 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16786041855812073\n",
            "epoch 1 - batch 180 - loss 1.9530924558639526 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1686430424451828\n",
            "epoch 1 - batch 190 - loss 2.1804006099700928 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.16986019909381866\n",
            "epoch 1 time: 189.62642788887024 sec\n",
            "epoch 2 - batch 10 - loss 3.0721895694732666 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.17781807482242584\n",
            "epoch 2 - batch 20 - loss 3.1284968852996826 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19214564561843872\n",
            "epoch 2 - batch 30 - loss 2.9170544147491455 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20079055428504944\n",
            "epoch 2 - batch 40 - loss 2.271946907043457 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19936522841453552\n",
            "epoch 2 - batch 50 - loss 1.8796021938323975 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19792968034744263\n",
            "epoch 2 - batch 60 - loss 1.9656192064285278 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19671688973903656\n",
            "epoch 2 - batch 70 - loss 1.9264525175094604 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19552774727344513\n",
            "epoch 2 - batch 80 - loss 2.22126841545105 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1941615492105484\n",
            "epoch 2 - batch 90 - loss 2.463963031768799 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19364459812641144\n",
            "epoch 2 - batch 100 - loss 2.563763380050659 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19423548877239227\n",
            "epoch 2 - batch 110 - loss 2.620999574661255 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19454647600650787\n",
            "epoch 2 - batch 120 - loss 2.5590527057647705 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19437547028064728\n",
            "epoch 2 - batch 130 - loss 2.8462812900543213 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19451408088207245\n",
            "epoch 2 - batch 140 - loss 2.5787885189056396 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1931600719690323\n",
            "epoch 2 - batch 150 - loss 2.413809061050415 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.1926785707473755\n",
            "epoch 2 - batch 160 - loss 1.9345616102218628 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19310477375984192\n",
            "epoch 2 - batch 170 - loss 1.8720722198486328 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19355304539203644\n",
            "epoch 2 - batch 180 - loss 1.7932794094085693 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19496682286262512\n",
            "epoch 2 - batch 190 - loss 2.0150351524353027 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19611284136772156\n",
            "epoch 2 time: 186.5743236541748 sec\n",
            "epoch 3 - batch 10 - loss 2.9600489139556885 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.19129464030265808\n",
            "epoch 3 - batch 20 - loss 2.939483880996704 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2077287882566452\n",
            "epoch 3 - batch 30 - loss 2.9226386547088623 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21537388861179352\n",
            "epoch 3 - batch 40 - loss 2.2680866718292236 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21203961968421936\n",
            "epoch 3 - batch 50 - loss 1.7477692365646362 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20990513265132904\n",
            "epoch 3 - batch 60 - loss 1.9259895086288452 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2082868367433548\n",
            "epoch 3 - batch 70 - loss 1.9336050748825073 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20676419138908386\n",
            "epoch 3 - batch 80 - loss 2.1573779582977295 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2046247273683548\n",
            "epoch 3 - batch 90 - loss 2.3854029178619385 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20286458730697632\n",
            "epoch 3 - batch 100 - loss 2.4096107482910156 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20249441266059875\n",
            "epoch 3 - batch 110 - loss 2.5984158515930176 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20240716636180878\n",
            "epoch 3 - batch 120 - loss 2.5263235569000244 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20209495723247528\n",
            "epoch 3 - batch 130 - loss 2.7297232151031494 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20173634588718414\n",
            "epoch 3 - batch 140 - loss 2.4085023403167725 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2006497085094452\n",
            "epoch 3 - batch 150 - loss 2.1693222522735596 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20118117332458496\n",
            "epoch 3 - batch 160 - loss 1.7417234182357788 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20304130017757416\n",
            "epoch 3 - batch 170 - loss 1.7853689193725586 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2039407193660736\n",
            "epoch 3 - batch 180 - loss 1.663434624671936 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20634610950946808\n",
            "epoch 3 - batch 190 - loss 1.9157885313034058 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20787858963012695\n",
            "epoch 3 time: 187.77846455574036 sec\n",
            "epoch 4 - batch 10 - loss 2.867255926132202 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20477120578289032\n",
            "epoch 4 - batch 20 - loss 2.7993578910827637 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22116351127624512\n",
            "epoch 4 - batch 30 - loss 2.7782816886901855 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22676710784435272\n",
            "epoch 4 - batch 40 - loss 2.10343599319458 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22314453125\n",
            "epoch 4 - batch 50 - loss 1.7515672445297241 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22012834250926971\n",
            "epoch 4 - batch 60 - loss 1.9255011081695557 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21783389151096344\n",
            "epoch 4 - batch 70 - loss 1.8139592409133911 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2152981460094452\n",
            "epoch 4 - batch 80 - loss 2.1287038326263428 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21227329969406128\n",
            "epoch 4 - batch 90 - loss 2.220095634460449 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21078559756278992\n",
            "epoch 4 - batch 100 - loss 2.2688279151916504 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2100139558315277\n",
            "epoch 4 - batch 110 - loss 2.4618725776672363 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20983664691448212\n",
            "epoch 4 - batch 120 - loss 2.5254898071289062 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.209519162774086\n",
            "epoch 4 - batch 130 - loss 2.5823652744293213 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20899724960327148\n",
            "epoch 4 - batch 140 - loss 2.153364658355713 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20801778137683868\n",
            "epoch 4 - batch 150 - loss 2.061086416244507 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2087165117263794\n",
            "epoch 4 - batch 160 - loss 1.6297805309295654 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2106497585773468\n",
            "epoch 4 - batch 170 - loss 1.704649806022644 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21239659190177917\n",
            "epoch 4 - batch 180 - loss 1.588997483253479 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21518167853355408\n",
            "epoch 4 - batch 190 - loss 1.7035647630691528 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2172403633594513\n",
            "epoch 4 time: 186.11957430839539 sec\n",
            "epoch 5 - batch 10 - loss 2.7023227214813232 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.20917968451976776\n",
            "epoch 5 - batch 20 - loss 2.7458271980285645 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22520926594734192\n",
            "epoch 5 - batch 30 - loss 2.586078405380249 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23030133545398712\n",
            "epoch 5 - batch 40 - loss 2.0126559734344482 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22742047905921936\n",
            "epoch 5 - batch 50 - loss 1.5861872434616089 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22652344405651093\n",
            "epoch 5 - batch 60 - loss 1.7844094038009644 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22584635019302368\n",
            "epoch 5 - batch 70 - loss 1.688408613204956 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2237802892923355\n",
            "epoch 5 - batch 80 - loss 1.9616729021072388 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22052176296710968\n",
            "epoch 5 - batch 90 - loss 2.288954496383667 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21869419515132904\n",
            "epoch 5 - batch 100 - loss 2.371497392654419 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2180301398038864\n",
            "epoch 5 - batch 110 - loss 2.386110544204712 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21746398508548737\n",
            "epoch 5 - batch 120 - loss 2.333423137664795 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21682943403720856\n",
            "epoch 5 - batch 130 - loss 2.621091842651367 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.216253861784935\n",
            "epoch 5 - batch 140 - loss 2.0579230785369873 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2152543067932129\n",
            "epoch 5 - batch 150 - loss 2.0454232692718506 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2159021645784378\n",
            "epoch 5 - batch 160 - loss 1.5945106744766235 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2182791531085968\n",
            "epoch 5 - batch 170 - loss 1.58574378490448 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21995142102241516\n",
            "epoch 5 - batch 180 - loss 1.4065392017364502 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22296936810016632\n",
            "epoch 5 - batch 190 - loss 1.6568174362182617 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2250719517469406\n",
            "epoch 5 time: 188.0288589000702 sec\n",
            "epoch 6 - batch 10 - loss 2.6027348041534424 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.21487164497375488\n",
            "epoch 6 - batch 20 - loss 2.659888505935669 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23201729357242584\n",
            "epoch 6 - batch 30 - loss 2.6399245262145996 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2385137677192688\n",
            "epoch 6 - batch 40 - loss 2.059988498687744 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23466099798679352\n",
            "epoch 6 - batch 50 - loss 1.6069098711013794 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2332589328289032\n",
            "epoch 6 - batch 60 - loss 1.7189180850982666 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23158946633338928\n",
            "epoch 6 - batch 70 - loss 1.6912528276443481 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22918526828289032\n",
            "epoch 6 - batch 80 - loss 1.8510667085647583 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2255859375\n",
            "epoch 6 - batch 90 - loss 2.0972445011138916 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2237568199634552\n",
            "epoch 6 - batch 100 - loss 2.214406967163086 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2232896238565445\n",
            "epoch 6 - batch 110 - loss 2.2436628341674805 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2231229692697525\n",
            "epoch 6 - batch 120 - loss 2.2494356632232666 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22254928946495056\n",
            "epoch 6 - batch 130 - loss 2.608355760574341 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2219286561012268\n",
            "epoch 6 - batch 140 - loss 2.0485634803771973 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22109773755073547\n",
            "epoch 6 - batch 150 - loss 1.9622045755386353 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22195684909820557\n",
            "epoch 6 - batch 160 - loss 1.498020887374878 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22456403076648712\n",
            "epoch 6 - batch 170 - loss 1.5054881572723389 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22628840804100037\n",
            "epoch 6 - batch 180 - loss 1.370393991470337 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22948908805847168\n",
            "epoch 6 - batch 190 - loss 1.579960823059082 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23156866431236267\n",
            "epoch 6 time: 186.75864338874817 sec\n",
            "epoch 7 - batch 10 - loss 2.5397651195526123 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2200055867433548\n",
            "epoch 7 - batch 20 - loss 2.602509021759033 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23864397406578064\n",
            "epoch 7 - batch 30 - loss 2.442995309829712 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24382440745830536\n",
            "epoch 7 - batch 40 - loss 1.97099769115448 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24024832248687744\n",
            "epoch 7 - batch 50 - loss 1.48814857006073 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23942522704601288\n",
            "epoch 7 - batch 60 - loss 1.6813619136810303 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23727212846279144\n",
            "epoch 7 - batch 70 - loss 1.635009765625 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2346540242433548\n",
            "epoch 7 - batch 80 - loss 1.8844314813613892 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23112095892429352\n",
            "epoch 7 - batch 90 - loss 2.08542799949646 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22855593264102936\n",
            "epoch 7 - batch 100 - loss 2.1898484230041504 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22762276232242584\n",
            "epoch 7 - batch 110 - loss 2.2466728687286377 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22754159569740295\n",
            "epoch 7 - batch 120 - loss 2.307047128677368 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22730886936187744\n",
            "epoch 7 - batch 130 - loss 2.4026124477386475 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22690805792808533\n",
            "epoch 7 - batch 140 - loss 1.9546773433685303 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22606027126312256\n",
            "epoch 7 - batch 150 - loss 1.8435938358306885 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22699962556362152\n",
            "epoch 7 - batch 160 - loss 1.496378779411316 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2297014445066452\n",
            "epoch 7 - batch 170 - loss 1.409655213356018 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2314371019601822\n",
            "epoch 7 - batch 180 - loss 1.3754085302352905 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23459357023239136\n",
            "epoch 7 - batch 190 - loss 1.5152734518051147 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23696252703666687\n",
            "epoch 7 time: 187.8562593460083 sec\n",
            "epoch 8 - batch 10 - loss 2.431251049041748 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22525112330913544\n",
            "epoch 8 - batch 20 - loss 2.4499988555908203 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24507533013820648\n",
            "epoch 8 - batch 30 - loss 2.397023916244507 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2504371404647827\n",
            "epoch 8 - batch 40 - loss 1.9366836547851562 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24685406684875488\n",
            "epoch 8 - batch 50 - loss 1.4730252027511597 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24542410671710968\n",
            "epoch 8 - batch 60 - loss 1.750458836555481 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24334077537059784\n",
            "epoch 8 - batch 70 - loss 1.6445640325546265 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24086017906665802\n",
            "epoch 8 - batch 80 - loss 1.8684157133102417 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.237060546875\n",
            "epoch 8 - batch 90 - loss 2.1283719539642334 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23451760411262512\n",
            "epoch 8 - batch 100 - loss 2.100005626678467 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23357701301574707\n",
            "epoch 8 - batch 110 - loss 2.0668394565582275 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23346185684204102\n",
            "epoch 8 - batch 120 - loss 2.0720412731170654 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23329612612724304\n",
            "epoch 8 - batch 130 - loss 2.3307900428771973 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23269660770893097\n",
            "epoch 8 - batch 140 - loss 1.8841544389724731 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23220862448215485\n",
            "epoch 8 - batch 150 - loss 1.8700231313705444 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23320312798023224\n",
            "epoch 8 - batch 160 - loss 1.4121532440185547 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23618513345718384\n",
            "epoch 8 - batch 170 - loss 1.423405408859253 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23767562210559845\n",
            "epoch 8 - batch 180 - loss 1.2119358777999878 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24082186818122864\n",
            "epoch 8 - batch 190 - loss 1.4764496088027954 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24320371448993683\n",
            "epoch 8 time: 186.80479526519775 sec\n",
            "epoch 9 - batch 10 - loss 2.2454993724823 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.22957588732242584\n",
            "epoch 9 - batch 20 - loss 2.360595226287842 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24933035671710968\n",
            "epoch 9 - batch 30 - loss 2.3950507640838623 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.25484561920166016\n",
            "epoch 9 - batch 40 - loss 1.8008500337600708 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.25133928656578064\n",
            "epoch 9 - batch 50 - loss 1.3749080896377563 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2504129409790039\n",
            "epoch 9 - batch 60 - loss 1.591473937034607 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24812592566013336\n",
            "epoch 9 - batch 70 - loss 1.5842736959457397 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24555563926696777\n",
            "epoch 9 - batch 80 - loss 1.8067775964736938 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24197125434875488\n",
            "epoch 9 - batch 90 - loss 1.9488096237182617 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23986855149269104\n",
            "epoch 9 - batch 100 - loss 1.9599615335464478 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.239547997713089\n",
            "epoch 9 - batch 110 - loss 2.0322768688201904 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23963575065135956\n",
            "epoch 9 - batch 120 - loss 1.9032495021820068 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23961123824119568\n",
            "epoch 9 - batch 130 - loss 2.4068329334259033 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23908181488513947\n",
            "epoch 9 - batch 140 - loss 1.7796437740325928 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23817561566829681\n",
            "epoch 9 - batch 150 - loss 1.819202184677124 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.23899181187152863\n",
            "epoch 9 - batch 160 - loss 1.3927854299545288 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24159109592437744\n",
            "epoch 9 - batch 170 - loss 1.3501431941986084 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24313944578170776\n",
            "epoch 9 - batch 180 - loss 1.1353589296340942 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24675564467906952\n",
            "epoch 9 - batch 190 - loss 1.325431227684021 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.248880997300148\n",
            "epoch 9 time: 187.91914558410645 sec\n",
            "epoch 10 - batch 10 - loss 2.271160840988159 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24054129421710968\n",
            "epoch 10 - batch 20 - loss 2.324415445327759 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.25796595215797424\n",
            "epoch 10 - batch 30 - loss 2.2134745121002197 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2621558904647827\n",
            "epoch 10 - batch 40 - loss 1.7658895254135132 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2582031190395355\n",
            "epoch 10 - batch 50 - loss 1.3874446153640747 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.25676897168159485\n",
            "epoch 10 - batch 60 - loss 1.5753480195999146 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.25480374693870544\n",
            "epoch 10 - batch 70 - loss 1.5167068243026733 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2519092857837677\n",
            "epoch 10 - batch 80 - loss 1.6620738506317139 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2477678507566452\n",
            "epoch 10 - batch 90 - loss 1.860308051109314 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24564732611179352\n",
            "epoch 10 - batch 100 - loss 1.877401351928711 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2453376054763794\n",
            "epoch 10 - batch 110 - loss 1.8452869653701782 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24566254019737244\n",
            "epoch 10 - batch 120 - loss 1.9613192081451416 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24554501473903656\n",
            "epoch 10 - batch 130 - loss 2.2220332622528076 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24529747664928436\n",
            "epoch 10 - batch 140 - loss 1.7321194410324097 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.245168998837471\n",
            "epoch 10 - batch 150 - loss 1.672598958015442 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24640066921710968\n",
            "epoch 10 - batch 160 - loss 1.151835560798645 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.24934779107570648\n",
            "epoch 10 - batch 170 - loss 1.3092944622039795 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.25098639726638794\n",
            "epoch 10 - batch 180 - loss 1.1194946765899658 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2545696794986725\n",
            "epoch 10 - batch 190 - loss 1.3799995183944702 - f1_macro_score 0.0 - sparse_categorical_accuracy 0.2566229999065399\n",
            "epoch 10 time: 186.77585363388062 sec\n",
            "Saving encoder weights locally\n",
            "Saving decoder weights locally\n",
            "Saved model weights locally\n",
            "Saving model with wandb\n",
            "Executing mocked noop symlink with arguments ('/content/gdrive/My Drive/src/identifier-suggestion-2020-05-06T07-24-34/models/saved/baseline/encoder.h5', './reports/wandb/run-20200506_072452-1jz7l1pn/encoder.h5')\n",
            "Executing mocked noop symlink with arguments ('/content/gdrive/My Drive/src/identifier-suggestion-2020-05-06T07-24-34/models/saved/baseline/decoder.h5', './reports/wandb/run-20200506_072452-1jz7l1pn/decoder.h5')\n",
            "Done saving model\n",
            "Test inputs:  [[   8   15  486   10    7    5  137 4043    4  140    3 1674  259   48\n",
            "    25    4   58    2    5  137 4043    4  140  132    3    7   17  486\n",
            "     2    5 1144  609 2062    3  486    2    5    9    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [   8   13   42    3    7    6 1144  609 2062    3    7    2    2    5\n",
            "     9    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n",
            "Predictions:  [[   4   49  478    3    3    3    3    3    3    3    3    3    3    3\n",
            "     3    3]\n",
            " [   4 1936   11 2655  156    3    3    3    3    3    3    3   95    3\n",
            "     3    3]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}