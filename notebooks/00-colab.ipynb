{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "00-colab.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/antonpetkoff/identifier-suggestion/blob/master/notebooks/00-colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeJd9knlVGS_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import utilities\n",
        "import os\n",
        "import shutil\n",
        "from subprocess import check_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_PqX9NDdEJh",
        "colab_type": "code",
        "outputId": "0cd84351-d212-4650-8fdb-8739397a4a4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dvcl4iohdWEi",
        "colab_type": "code",
        "outputId": "d42c70e5-4741-4bc4-85e9-08bcf942b5d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%env WORKSPACE_DIR=/content/gdrive/My Drive/src\n",
        "\n",
        "# TODO: how can one read an environment variable?!?\n",
        "%cd '/content/gdrive/My Drive/src'"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "env: WORKSPACE_DIR=/content/gdrive/My Drive/src\n",
            "/content/gdrive/My Drive/src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNR4ZqljgeyP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "timestamp = check_output(['date', '-u', \"+%Y-%m-%dT%H-%M-%S\"]).decode('utf-8').strip()\n",
        "\n",
        "os.environ['PROJECT_DIR'] = os.path.join(\n",
        "    os.environ['WORKSPACE_DIR'],\n",
        "    f'identifier-suggestion-{timestamp}',\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PoI39h1dEJ0",
        "colab_type": "code",
        "outputId": "a01a430f-b952-4ac9-c620-dad5b52a775b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "source": [
        "!git clone https://github.com/antonpetkoff/identifier-suggestion.git --depth 1 \"${PROJECT_DIR}\""
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into '/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45'...\n",
            "remote: Enumerating objects: 62, done.\u001b[K\n",
            "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
            "remote: Compressing objects: 100% (54/54), done.\u001b[K\n",
            "remote: Total 62 (delta 0), reused 38 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (62/62), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mki1yqMgixt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir(os.environ['PROJECT_DIR'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4HjKIGx4i2dr",
        "colab_type": "code",
        "outputId": "57af7d36-f9d5-4b06-d9e2-8c3ec14f3696",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "!pwd\n",
        "!ls -l"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45\n",
            "total 53\n",
            "-rw------- 1 root root 35149 May  5 06:53 LICENSE\n",
            "drwx------ 2 root root  4096 May  5 06:53 notebooks\n",
            "-rw------- 1 root root  6632 May  5 06:53 README.md\n",
            "drwx------ 2 root root  4096 May  5 06:53 requirements\n",
            "drwx------ 9 root root  4096 May  5 06:53 src\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCr-lrn4SRhW",
        "colab_type": "code",
        "outputId": "ef273288-4af3-464c-e1dc-25a5d741b674",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M7BkvE4dEJ-",
        "colab_type": "code",
        "outputId": "068a8fda-8940-4d56-cc8d-e777feb49d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Google Colab has standard libraries like numpy, pandas, matplotlib and TF (of course) pre-installed\n",
        "!pip install -r requirements/colab.txt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting javalang==0.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/e0/12344443d66b9a84844171be90112892a371da6db09866741774b8bc0a2f/javalang-0.13.0-py3-none-any.whl\n",
            "Collecting python-dotenv==0.13.0\n",
            "  Downloading https://files.pythonhosted.org/packages/cb/2a/07f87440444fdf2c5870a710b6770d766a1c7df9c827b0c90e807f1fb4c5/python_dotenv-0.13.0-py2.py3-none-any.whl\n",
            "Collecting wandb==0.8.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2d/c9/ebbcefa6ef2ba14a7c62a4ee4415a5fecef8fac5e4d1b4e22af26fd9fe22/wandb-0.8.35-py2.py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4MB 9.1MB/s \n",
            "\u001b[?25hCollecting tables==3.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/c3/8fd9e3bb21872f9d69eb93b3014c86479864cca94e625fd03713ccacec80/tables-3.6.1-cp36-cp36m-manylinux1_x86_64.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 36.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from javalang==0.13.0->-r requirements/colab.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.13)\n",
            "Collecting watchdog>=0.8.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/c3/ed6d992006837e011baca89476a4bbffb0a91602432f73bd4473816c76e2/watchdog-0.10.2.tar.gz (95kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 15.4MB/s \n",
            "\u001b[?25hCollecting GitPython>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/33/917e6fde1cad13daa7053f39b7c8af3be287314f75f1b1ea8d3fe37a8571/GitPython-3.1.2-py3-none-any.whl (451kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 57.0MB/s \n",
            "\u001b[?25hCollecting configparser>=3.8.1\n",
            "  Downloading https://files.pythonhosted.org/packages/4b/6b/01baa293090240cf0562cc5eccb69c6f5006282127f2b846fad011305c79/configparser-5.0.0-py3-none-any.whl\n",
            "Collecting sentry-sdk>=0.4.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/7e/19545324e83db4522b885808cd913c3b93ecc0c88b03e037b78c6a417fa8/sentry_sdk-0.14.3-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 59.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (7.352.0)\n",
            "Requirement already satisfied: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.23.0)\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (7.1.2)\n",
            "Collecting docker-pycreds>=0.4.0\n",
            "  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (5.4.8)\n",
            "Collecting subprocess32>=3.5.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 16.3MB/s \n",
            "\u001b[?25hCollecting shortuuid>=0.5.0\n",
            "  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.8.1)\n",
            "Collecting gql==0.2.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c4/6f/cf9a3056045518f06184e804bae89390eb706168349daa9dff8ac609962a/gql-0.2.0.tar.gz\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from tables==3.6.1->-r requirements/colab.txt (line 4)) (1.18.3)\n",
            "Requirement already satisfied: numexpr>=2.6.2 in /usr/local/lib/python3.6/dist-packages (from tables==3.6.1->-r requirements/colab.txt (line 4)) (2.7.1)\n",
            "Collecting pathtools>=0.1.1\n",
            "  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (1.24.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from sentry-sdk>=0.4.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.9)\n",
            "Collecting graphql-core<2,>=0.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/89/00ad5e07524d8c523b14d70c685e0299a8b0de6d0727e368c41b89b7ed0b/graphql-core-1.1.tar.gz (70kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 12.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from gql==0.2.0->wandb==0.8.35->-r requirements/colab.txt (line 3)) (2.3)\n",
            "Collecting smmap<4,>=3.0.1\n",
            "  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: watchdog, subprocess32, gql, pathtools, graphql-core\n",
            "  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for watchdog: filename=watchdog-0.10.2-cp36-none-any.whl size=73605 sha256=40387e722cc4ab5feca79efe61e2088372400cde251b3e7c6e01a05bcd74c6ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/ed/6c/028dea90d31b359cd2a7c8b0da4db80e41d24a59614154072e\n",
            "  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=71de681307c73db0483f0eb3fd247057c9f47244fc9edc11c800e06a3d4875e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n",
            "  Building wheel for gql (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gql: filename=gql-0.2.0-cp36-none-any.whl size=7630 sha256=dcdd90e3849e4ad344b5142b0a9a884e1eebfe25c90d0cb4fa78786ab6566794\n",
            "  Stored in directory: /root/.cache/pip/wheels/ce/0e/7b/58a8a5268655b3ad74feef5aa97946f0addafb3cbb6bd2da23\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8784 sha256=6a0132a8d4efca8941cf98c101e344b665c1e308eb357709b4fb91f47b04078a\n",
            "  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n",
            "  Building wheel for graphql-core (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for graphql-core: filename=graphql_core-1.1-cp36-none-any.whl size=104650 sha256=fdea757b3f25469c242b8100a259e762a84ab882706371e78fa93dbdfb6c41de\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/99/d7/c424029bb0fe910c63b68dbf2aa20d3283d023042521bcd7d5\n",
            "Successfully built watchdog subprocess32 gql pathtools graphql-core\n",
            "Installing collected packages: javalang, python-dotenv, pathtools, watchdog, smmap, gitdb, GitPython, configparser, sentry-sdk, docker-pycreds, subprocess32, shortuuid, graphql-core, gql, wandb, tables\n",
            "  Found existing installation: tables 3.4.4\n",
            "    Uninstalling tables-3.4.4:\n",
            "      Successfully uninstalled tables-3.4.4\n",
            "Successfully installed GitPython-3.1.2 configparser-5.0.0 docker-pycreds-0.4.0 gitdb-4.0.5 gql-0.2.0 graphql-core-1.1 javalang-0.13.0 pathtools-0.1.2 python-dotenv-0.13.0 sentry-sdk-0.14.3 shortuuid-1.0.1 smmap-3.0.4 subprocess32-3.5.4 tables-3.6.1 wandb-0.8.35 watchdog-0.10.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASrqt3o4TP5E",
        "colab_type": "code",
        "outputId": "feb6190b-8ecd-41ff-e097-272de9d6310e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# provide secrets to the project, e.g. access to wandb\n",
        "shutil.copy(\n",
        "    os.path.join(os.environ['WORKSPACE_DIR'], 'secrets/.env'),\n",
        "    os.environ['PROJECT_DIR']\n",
        ")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45/.env'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBhbZ4muuveC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# monkey-patch (mock) os.symlink to be a noop, because wandb.save() uses it, but it is not supported by Google Colab Notebooks\n",
        "os.symlink = lambda *x: print('Executing mocked noop symlink with arguments', x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY3fkLJIm7ja",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3b5e0310-0926-4fc9-b27c-2b1ac15edd4f"
      },
      "source": [
        "from argparse import Namespace\n",
        "from src.pipelines.baseline import run\n",
        "\n",
        "params = {\n",
        "  'file_data_raw': '../data/interim/method-names-rich/elasticsearch.csv',\n",
        "  'file_model_dir': 'models/saved/baseline/',\n",
        "  'dir_preprocessed_data': '../data/interim/preprocessed/',\n",
        "  'max_input_length': 200,\n",
        "  'max_output_length': 8,\n",
        "  'input_vocab_size': 20000,\n",
        "  'input_embedding_dim': 128,\n",
        "  'output_vocab_size': 6000,\n",
        "  'output_embedding_dim': 128,\n",
        "  'latent_dim': 512,\n",
        "  'learning_rate': 0.0001,\n",
        "  'epochs': 10,\n",
        "  'batch_size': 512,\n",
        "  'random_seed': 1,\n",
        "}\n",
        "\n",
        "run(Namespace(**params))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Experiment parameters:  Namespace(batch_size=512, dir_preprocessed_data='../data/interim/preprocessed/', epochs=10, file_data_raw='../data/interim/method-names-rich/elasticsearch.csv', file_model_dir='models/saved/baseline/', input_embedding_dim=128, input_vocab_size=20000, latent_dim=512, learning_rate=0.0001, max_input_length=200, max_output_length=8, output_embedding_dim=128, output_vocab_size=6000, random_seed=1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Logging results to <a href=\"https://wandb.com\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://app.wandb.ai/antonpetkoff/identifier-suggestion\" target=\"_blank\">https://app.wandb.ai/antonpetkoff/identifier-suggestion</a><br/>\n",
              "                Run page: <a href=\"https://app.wandb.ai/antonpetkoff/identifier-suggestion/runs/yn2vhb36\" target=\"_blank\">https://app.wandb.ai/antonpetkoff/identifier-suggestion/runs/yn2vhb36</a><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Loading preprocessed files...\n",
            "Loaded input vocabulary.\n",
            "Loaded output vocabulary.\n",
            "Loaded preprocessed files.\n",
            "example_X shape:  (512, 200)\n",
            "example_Y shape:  (512, 8)\n",
            "total loss: 3.4512858390808105, epoch 1, batch 5\n",
            "total loss: 4.5801801681518555, epoch 1, batch 10\n",
            "total loss: 3.476195812225342, epoch 1, batch 15\n",
            "total loss: 3.3813846111297607, epoch 1, batch 20\n",
            "total loss: 3.65224027633667, epoch 1, batch 25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Network error resolved after 0:00:24.270104, resuming normal operation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "total loss: 3.3728575706481934, epoch 1, batch 30\n",
            "total loss: 3.361548662185669, epoch 1, batch 35\n",
            "total loss: 2.7298834323883057, epoch 1, batch 40\n",
            "total loss: 2.392657995223999, epoch 1, batch 45\n",
            "total loss: 2.0537097454071045, epoch 1, batch 50\n",
            "total loss: 2.2095837593078613, epoch 1, batch 55\n",
            "total loss: 1.9058653116226196, epoch 1, batch 60\n",
            "total loss: 2.442979574203491, epoch 1, batch 65\n",
            "total loss: 2.169740915298462, epoch 1, batch 70\n",
            "total loss: 2.413036584854126, epoch 1, batch 75\n",
            "total loss: 2.2418856620788574, epoch 1, batch 80\n",
            "total loss: 2.367259979248047, epoch 1, batch 85\n",
            "total loss: 2.7842862606048584, epoch 1, batch 90\n",
            "total loss: 3.197749614715576, epoch 1, batch 95\n",
            "total loss: 3.0554401874542236, epoch 1, batch 100\n",
            "total loss: 3.358518123626709, epoch 1, batch 105\n",
            "total loss: 2.561542272567749, epoch 1, batch 110\n",
            "total loss: 3.375640392303467, epoch 1, batch 115\n",
            "total loss: 2.9185967445373535, epoch 1, batch 120\n",
            "total loss: 2.472261428833008, epoch 1, batch 125\n",
            "total loss: 3.797147035598755, epoch 1, batch 130\n",
            "total loss: 2.976585626602173, epoch 1, batch 135\n",
            "total loss: 3.8013341426849365, epoch 1, batch 140\n",
            "total loss: 2.4555561542510986, epoch 1, batch 145\n",
            "total loss: 3.101166248321533, epoch 1, batch 150\n",
            "total loss: 3.351351499557495, epoch 1, batch 155\n",
            "total loss: 2.351454257965088, epoch 1, batch 160\n",
            "total loss: 2.5134658813476562, epoch 1, batch 165\n",
            "total loss: 1.658558964729309, epoch 1, batch 170\n",
            "total loss: 1.7021485567092896, epoch 1, batch 175\n",
            "total loss: 3.0206124782562256, epoch 1, batch 180\n",
            "total loss: 1.6118470430374146, epoch 1, batch 185\n",
            "total loss: 1.6609525680541992, epoch 1, batch 190\n",
            "total loss: 2.73099684715271, epoch 1, batch 195\n",
            "total loss: 2.4570300579071045, epoch 2, batch 5\n",
            "total loss: 4.212200164794922, epoch 2, batch 10\n",
            "total loss: 3.177957773208618, epoch 2, batch 15\n",
            "total loss: 3.209838628768921, epoch 2, batch 20\n",
            "total loss: 3.2853312492370605, epoch 2, batch 25\n",
            "total loss: 3.245699644088745, epoch 2, batch 30\n",
            "total loss: 3.145294189453125, epoch 2, batch 35\n",
            "total loss: 2.684420108795166, epoch 2, batch 40\n",
            "total loss: 2.2940468788146973, epoch 2, batch 45\n",
            "total loss: 1.952890396118164, epoch 2, batch 50\n",
            "total loss: 2.0990445613861084, epoch 2, batch 55\n",
            "total loss: 1.736413598060608, epoch 2, batch 60\n",
            "total loss: 2.360844850540161, epoch 2, batch 65\n",
            "total loss: 2.0502164363861084, epoch 2, batch 70\n",
            "total loss: 2.3168551921844482, epoch 2, batch 75\n",
            "total loss: 2.177187204360962, epoch 2, batch 80\n",
            "total loss: 2.2552292346954346, epoch 2, batch 85\n",
            "total loss: 2.5476338863372803, epoch 2, batch 90\n",
            "total loss: 2.909899950027466, epoch 2, batch 95\n",
            "total loss: 2.707078456878662, epoch 2, batch 100\n",
            "total loss: 3.0891973972320557, epoch 2, batch 105\n",
            "total loss: 2.2541260719299316, epoch 2, batch 110\n",
            "total loss: 3.081007242202759, epoch 2, batch 115\n",
            "total loss: 2.6951756477355957, epoch 2, batch 120\n",
            "total loss: 2.142883777618408, epoch 2, batch 125\n",
            "total loss: 3.604201078414917, epoch 2, batch 130\n",
            "total loss: 2.6684651374816895, epoch 2, batch 135\n",
            "total loss: 3.511324644088745, epoch 2, batch 140\n",
            "total loss: 2.280158519744873, epoch 2, batch 145\n",
            "total loss: 2.9228365421295166, epoch 2, batch 150\n",
            "total loss: 3.1570754051208496, epoch 2, batch 155\n",
            "total loss: 2.0367207527160645, epoch 2, batch 160\n",
            "total loss: 2.3404250144958496, epoch 2, batch 165\n",
            "total loss: 1.5865331888198853, epoch 2, batch 170\n",
            "total loss: 1.6223949193954468, epoch 2, batch 175\n",
            "total loss: 2.6673550605773926, epoch 2, batch 180\n",
            "total loss: 1.436889886856079, epoch 2, batch 185\n",
            "total loss: 1.4978787899017334, epoch 2, batch 190\n",
            "total loss: 2.621748447418213, epoch 2, batch 195\n",
            "total loss: 2.362389326095581, epoch 3, batch 5\n",
            "total loss: 3.9674794673919678, epoch 3, batch 10\n",
            "total loss: 2.930469274520874, epoch 3, batch 15\n",
            "total loss: 2.9811723232269287, epoch 3, batch 20\n",
            "total loss: 3.083848237991333, epoch 3, batch 25\n",
            "total loss: 3.083967924118042, epoch 3, batch 30\n",
            "total loss: 3.0381970405578613, epoch 3, batch 35\n",
            "total loss: 2.503229856491089, epoch 3, batch 40\n",
            "total loss: 2.1611266136169434, epoch 3, batch 45\n",
            "total loss: 1.7373073101043701, epoch 3, batch 50\n",
            "total loss: 1.967569351196289, epoch 3, batch 55\n",
            "total loss: 1.6267321109771729, epoch 3, batch 60\n",
            "total loss: 2.223548650741577, epoch 3, batch 65\n",
            "total loss: 1.945451021194458, epoch 3, batch 70\n",
            "total loss: 2.1156389713287354, epoch 3, batch 75\n",
            "total loss: 2.0441362857818604, epoch 3, batch 80\n",
            "total loss: 2.192556142807007, epoch 3, batch 85\n",
            "total loss: 2.40476655960083, epoch 3, batch 90\n",
            "total loss: 2.4967925548553467, epoch 3, batch 95\n",
            "total loss: 2.487100601196289, epoch 3, batch 100\n",
            "total loss: 3.0475430488586426, epoch 3, batch 105\n",
            "total loss: 2.0816149711608887, epoch 3, batch 110\n",
            "total loss: 2.8280560970306396, epoch 3, batch 115\n",
            "total loss: 2.497871160507202, epoch 3, batch 120\n",
            "total loss: 2.045714855194092, epoch 3, batch 125\n",
            "total loss: 3.5156590938568115, epoch 3, batch 130\n",
            "total loss: 2.5179221630096436, epoch 3, batch 135\n",
            "total loss: 3.278076648712158, epoch 3, batch 140\n",
            "total loss: 2.0263192653656006, epoch 3, batch 145\n",
            "total loss: 2.764930248260498, epoch 3, batch 150\n",
            "total loss: 2.9480624198913574, epoch 3, batch 155\n",
            "total loss: 1.7309191226959229, epoch 3, batch 160\n",
            "total loss: 2.092660665512085, epoch 3, batch 165\n",
            "total loss: 1.440759301185608, epoch 3, batch 170\n",
            "total loss: 1.5102145671844482, epoch 3, batch 175\n",
            "total loss: 1.9938651323318481, epoch 3, batch 180\n",
            "total loss: 1.311439871788025, epoch 3, batch 185\n",
            "total loss: 1.3325186967849731, epoch 3, batch 190\n",
            "total loss: 2.494933605194092, epoch 3, batch 195\n",
            "total loss: 2.3188130855560303, epoch 4, batch 5\n",
            "total loss: 3.8395543098449707, epoch 4, batch 10\n",
            "total loss: 2.7464447021484375, epoch 4, batch 15\n",
            "total loss: 2.8401589393615723, epoch 4, batch 20\n",
            "total loss: 2.9775044918060303, epoch 4, batch 25\n",
            "total loss: 2.970212459564209, epoch 4, batch 30\n",
            "total loss: 2.964008092880249, epoch 4, batch 35\n",
            "total loss: 2.3594136238098145, epoch 4, batch 40\n",
            "total loss: 2.02634334564209, epoch 4, batch 45\n",
            "total loss: 1.588042974472046, epoch 4, batch 50\n",
            "total loss: 1.8546812534332275, epoch 4, batch 55\n",
            "total loss: 1.5307081937789917, epoch 4, batch 60\n",
            "total loss: 2.1845104694366455, epoch 4, batch 65\n",
            "total loss: 1.882619857788086, epoch 4, batch 70\n",
            "total loss: 2.025076150894165, epoch 4, batch 75\n",
            "total loss: 2.0297298431396484, epoch 4, batch 80\n",
            "total loss: 2.156977415084839, epoch 4, batch 85\n",
            "total loss: 2.4030778408050537, epoch 4, batch 90\n",
            "total loss: 2.4013543128967285, epoch 4, batch 95\n",
            "total loss: 2.4315197467803955, epoch 4, batch 100\n",
            "total loss: 2.9614713191986084, epoch 4, batch 105\n",
            "total loss: 2.0065107345581055, epoch 4, batch 110\n",
            "total loss: 2.8153235912323, epoch 4, batch 115\n",
            "total loss: 2.434150218963623, epoch 4, batch 120\n",
            "total loss: 1.933111310005188, epoch 4, batch 125\n",
            "total loss: 3.3789401054382324, epoch 4, batch 130\n",
            "total loss: 2.504408121109009, epoch 4, batch 135\n",
            "total loss: 3.1987321376800537, epoch 4, batch 140\n",
            "total loss: 2.0004799365997314, epoch 4, batch 145\n",
            "total loss: 2.728125810623169, epoch 4, batch 150\n",
            "total loss: 2.8189494609832764, epoch 4, batch 155\n",
            "total loss: 1.5886703729629517, epoch 4, batch 160\n",
            "total loss: 2.041368007659912, epoch 4, batch 165\n",
            "total loss: 1.3292961120605469, epoch 4, batch 170\n",
            "total loss: 1.4526138305664062, epoch 4, batch 175\n",
            "total loss: 1.6732290983200073, epoch 4, batch 180\n",
            "total loss: 1.1473122835159302, epoch 4, batch 185\n",
            "total loss: 1.2425607442855835, epoch 4, batch 190\n",
            "total loss: 2.3877604007720947, epoch 4, batch 195\n",
            "total loss: 2.238004684448242, epoch 5, batch 5\n",
            "total loss: 3.706090211868286, epoch 5, batch 10\n",
            "total loss: 2.6767659187316895, epoch 5, batch 15\n",
            "total loss: 2.753323793411255, epoch 5, batch 20\n",
            "total loss: 2.884197950363159, epoch 5, batch 25\n",
            "total loss: 2.869077205657959, epoch 5, batch 30\n",
            "total loss: 2.9181556701660156, epoch 5, batch 35\n",
            "total loss: 2.261586904525757, epoch 5, batch 40\n",
            "total loss: 1.9461852312088013, epoch 5, batch 45\n",
            "total loss: 1.5079281330108643, epoch 5, batch 50\n",
            "total loss: 1.7946587800979614, epoch 5, batch 55\n",
            "total loss: 1.4581984281539917, epoch 5, batch 60\n",
            "total loss: 2.113830327987671, epoch 5, batch 65\n",
            "total loss: 1.8228099346160889, epoch 5, batch 70\n",
            "total loss: 1.9310344457626343, epoch 5, batch 75\n",
            "total loss: 1.949983835220337, epoch 5, batch 80\n",
            "total loss: 2.0521204471588135, epoch 5, batch 85\n",
            "total loss: 2.3350634574890137, epoch 5, batch 90\n",
            "total loss: 2.377859354019165, epoch 5, batch 95\n",
            "total loss: 2.3782553672790527, epoch 5, batch 100\n",
            "total loss: 2.811743974685669, epoch 5, batch 105\n",
            "total loss: 1.9433619976043701, epoch 5, batch 110\n",
            "total loss: 2.7431957721710205, epoch 5, batch 115\n",
            "total loss: 2.343141794204712, epoch 5, batch 120\n",
            "total loss: 1.8403902053833008, epoch 5, batch 125\n",
            "total loss: 3.298337936401367, epoch 5, batch 130\n",
            "total loss: 2.4306681156158447, epoch 5, batch 135\n",
            "total loss: 3.133361339569092, epoch 5, batch 140\n",
            "total loss: 1.8209855556488037, epoch 5, batch 145\n",
            "total loss: 2.63954496383667, epoch 5, batch 150\n",
            "total loss: 2.7317707538604736, epoch 5, batch 155\n",
            "total loss: 1.5243383646011353, epoch 5, batch 160\n",
            "total loss: 1.9117108583450317, epoch 5, batch 165\n",
            "total loss: 1.2543675899505615, epoch 5, batch 170\n",
            "total loss: 1.349062204360962, epoch 5, batch 175\n",
            "total loss: 1.5024234056472778, epoch 5, batch 180\n",
            "total loss: 1.0390437841415405, epoch 5, batch 185\n",
            "total loss: 1.1712310314178467, epoch 5, batch 190\n",
            "total loss: 2.3060128688812256, epoch 5, batch 195\n",
            "total loss: 2.1590373516082764, epoch 6, batch 5\n",
            "total loss: 3.542241334915161, epoch 6, batch 10\n",
            "total loss: 2.5409061908721924, epoch 6, batch 15\n",
            "total loss: 2.668073892593384, epoch 6, batch 20\n",
            "total loss: 2.736574411392212, epoch 6, batch 25\n",
            "total loss: 2.7217347621917725, epoch 6, batch 30\n",
            "total loss: 2.8726789951324463, epoch 6, batch 35\n",
            "total loss: 2.1071276664733887, epoch 6, batch 40\n",
            "total loss: 1.9048244953155518, epoch 6, batch 45\n",
            "total loss: 1.4409204721450806, epoch 6, batch 50\n",
            "total loss: 1.697324514389038, epoch 6, batch 55\n",
            "total loss: 1.3814512491226196, epoch 6, batch 60\n",
            "total loss: 2.0097761154174805, epoch 6, batch 65\n",
            "total loss: 1.7249581813812256, epoch 6, batch 70\n",
            "total loss: 1.8103440999984741, epoch 6, batch 75\n",
            "total loss: 1.8880252838134766, epoch 6, batch 80\n",
            "total loss: 1.9303165674209595, epoch 6, batch 85\n",
            "total loss: 2.199439287185669, epoch 6, batch 90\n",
            "total loss: 2.336458444595337, epoch 6, batch 95\n",
            "total loss: 2.305379867553711, epoch 6, batch 100\n",
            "total loss: 2.755593776702881, epoch 6, batch 105\n",
            "total loss: 1.8459761142730713, epoch 6, batch 110\n",
            "total loss: 2.6295621395111084, epoch 6, batch 115\n",
            "total loss: 2.291717052459717, epoch 6, batch 120\n",
            "total loss: 1.729287028312683, epoch 6, batch 125\n",
            "total loss: 3.151817798614502, epoch 6, batch 130\n",
            "total loss: 2.347541570663452, epoch 6, batch 135\n",
            "total loss: 3.0067405700683594, epoch 6, batch 140\n",
            "total loss: 1.6645914316177368, epoch 6, batch 145\n",
            "total loss: 2.597956418991089, epoch 6, batch 150\n",
            "total loss: 2.5887701511383057, epoch 6, batch 155\n",
            "total loss: 1.4424930810928345, epoch 6, batch 160\n",
            "total loss: 1.7807624340057373, epoch 6, batch 165\n",
            "total loss: 1.2323111295700073, epoch 6, batch 170\n",
            "total loss: 1.295353651046753, epoch 6, batch 175\n",
            "total loss: 1.3788584470748901, epoch 6, batch 180\n",
            "total loss: 0.9187965393066406, epoch 6, batch 185\n",
            "total loss: 1.0829957723617554, epoch 6, batch 190\n",
            "total loss: 2.1608693599700928, epoch 6, batch 195\n",
            "total loss: 2.0622894763946533, epoch 7, batch 5\n",
            "total loss: 3.4298157691955566, epoch 7, batch 10\n",
            "total loss: 2.3994834423065186, epoch 7, batch 15\n",
            "total loss: 2.5505740642547607, epoch 7, batch 20\n",
            "total loss: 2.6564228534698486, epoch 7, batch 25\n",
            "total loss: 2.563417911529541, epoch 7, batch 30\n",
            "total loss: 2.78722882270813, epoch 7, batch 35\n",
            "total loss: 1.9736863374710083, epoch 7, batch 40\n",
            "total loss: 1.8061209917068481, epoch 7, batch 45\n",
            "total loss: 1.365887999534607, epoch 7, batch 50\n",
            "total loss: 1.634597897529602, epoch 7, batch 55\n",
            "total loss: 1.252166748046875, epoch 7, batch 60\n",
            "total loss: 1.8723957538604736, epoch 7, batch 65\n",
            "total loss: 1.6107183694839478, epoch 7, batch 70\n",
            "total loss: 1.6508643627166748, epoch 7, batch 75\n",
            "total loss: 1.8153893947601318, epoch 7, batch 80\n",
            "total loss: 1.788025140762329, epoch 7, batch 85\n",
            "total loss: 2.0909018516540527, epoch 7, batch 90\n",
            "total loss: 2.2250611782073975, epoch 7, batch 95\n",
            "total loss: 2.1628851890563965, epoch 7, batch 100\n",
            "total loss: 2.654311418533325, epoch 7, batch 105\n",
            "total loss: 1.760455846786499, epoch 7, batch 110\n",
            "total loss: 2.5805511474609375, epoch 7, batch 115\n",
            "total loss: 2.1413638591766357, epoch 7, batch 120\n",
            "total loss: 1.5454922914505005, epoch 7, batch 125\n",
            "total loss: 3.080627918243408, epoch 7, batch 130\n",
            "total loss: 2.2845988273620605, epoch 7, batch 135\n",
            "total loss: 2.9423234462738037, epoch 7, batch 140\n",
            "total loss: 1.5117857456207275, epoch 7, batch 145\n",
            "total loss: 2.5296504497528076, epoch 7, batch 150\n",
            "total loss: 2.4834206104278564, epoch 7, batch 155\n",
            "total loss: 1.3801259994506836, epoch 7, batch 160\n",
            "total loss: 1.6089894771575928, epoch 7, batch 165\n",
            "total loss: 1.1050482988357544, epoch 7, batch 170\n",
            "total loss: 1.201002836227417, epoch 7, batch 175\n",
            "total loss: 1.2799102067947388, epoch 7, batch 180\n",
            "total loss: 0.7218950986862183, epoch 7, batch 185\n",
            "total loss: 0.973206102848053, epoch 7, batch 190\n",
            "total loss: 2.0540454387664795, epoch 7, batch 195\n",
            "total loss: 1.9831733703613281, epoch 8, batch 5\n",
            "total loss: 3.255005121231079, epoch 8, batch 10\n",
            "total loss: 2.2645580768585205, epoch 8, batch 15\n",
            "total loss: 2.4346072673797607, epoch 8, batch 20\n",
            "total loss: 2.552344560623169, epoch 8, batch 25\n",
            "total loss: 2.4423561096191406, epoch 8, batch 30\n",
            "total loss: 2.6689722537994385, epoch 8, batch 35\n",
            "total loss: 1.9081250429153442, epoch 8, batch 40\n",
            "total loss: 1.733763575553894, epoch 8, batch 45\n",
            "total loss: 1.297261357307434, epoch 8, batch 50\n",
            "total loss: 1.5406557321548462, epoch 8, batch 55\n",
            "total loss: 1.1400316953659058, epoch 8, batch 60\n",
            "total loss: 1.7350374460220337, epoch 8, batch 65\n",
            "total loss: 1.4969117641448975, epoch 8, batch 70\n",
            "total loss: 1.5230718851089478, epoch 8, batch 75\n",
            "total loss: 1.7086387872695923, epoch 8, batch 80\n",
            "total loss: 1.6917407512664795, epoch 8, batch 85\n",
            "total loss: 1.977691411972046, epoch 8, batch 90\n",
            "total loss: 2.1755518913269043, epoch 8, batch 95\n",
            "total loss: 2.0218148231506348, epoch 8, batch 100\n",
            "total loss: 2.5061581134796143, epoch 8, batch 105\n",
            "total loss: 1.7044589519500732, epoch 8, batch 110\n",
            "total loss: 2.4946064949035645, epoch 8, batch 115\n",
            "total loss: 2.048985242843628, epoch 8, batch 120\n",
            "total loss: 1.3894659280776978, epoch 8, batch 125\n",
            "total loss: 2.9076316356658936, epoch 8, batch 130\n",
            "total loss: 2.181114912033081, epoch 8, batch 135\n",
            "total loss: 2.8399815559387207, epoch 8, batch 140\n",
            "total loss: 1.331038475036621, epoch 8, batch 145\n",
            "total loss: 2.4120640754699707, epoch 8, batch 150\n",
            "total loss: 2.380760908126831, epoch 8, batch 155\n",
            "total loss: 1.2494312524795532, epoch 8, batch 160\n",
            "total loss: 1.4918806552886963, epoch 8, batch 165\n",
            "total loss: 1.0178393125534058, epoch 8, batch 170\n",
            "total loss: 1.1073858737945557, epoch 8, batch 175\n",
            "total loss: 1.1557484865188599, epoch 8, batch 180\n",
            "total loss: 0.6552775502204895, epoch 8, batch 185\n",
            "total loss: 0.8874877095222473, epoch 8, batch 190\n",
            "total loss: 1.9716107845306396, epoch 8, batch 195\n",
            "total loss: 1.9080171585083008, epoch 9, batch 5\n",
            "total loss: 3.1313531398773193, epoch 9, batch 10\n",
            "total loss: 2.1371676921844482, epoch 9, batch 15\n",
            "total loss: 2.3941426277160645, epoch 9, batch 20\n",
            "total loss: 2.434699535369873, epoch 9, batch 25\n",
            "total loss: 2.3413734436035156, epoch 9, batch 30\n",
            "total loss: 2.6299633979797363, epoch 9, batch 35\n",
            "total loss: 1.8125503063201904, epoch 9, batch 40\n",
            "total loss: 1.6441806554794312, epoch 9, batch 45\n",
            "total loss: 1.1984567642211914, epoch 9, batch 50\n",
            "total loss: 1.451634407043457, epoch 9, batch 55\n",
            "total loss: 1.0138696432113647, epoch 9, batch 60\n",
            "total loss: 1.6059163808822632, epoch 9, batch 65\n",
            "total loss: 1.3871065378189087, epoch 9, batch 70\n",
            "total loss: 1.3886886835098267, epoch 9, batch 75\n",
            "total loss: 1.6439601182937622, epoch 9, batch 80\n",
            "total loss: 1.598725438117981, epoch 9, batch 85\n",
            "total loss: 1.868729591369629, epoch 9, batch 90\n",
            "total loss: 2.1000564098358154, epoch 9, batch 95\n",
            "total loss: 1.836600661277771, epoch 9, batch 100\n",
            "total loss: 2.355156660079956, epoch 9, batch 105\n",
            "total loss: 1.6264818906784058, epoch 9, batch 110\n",
            "total loss: 2.3673155307769775, epoch 9, batch 115\n",
            "total loss: 1.9653112888336182, epoch 9, batch 120\n",
            "total loss: 1.3405011892318726, epoch 9, batch 125\n",
            "total loss: 2.749677896499634, epoch 9, batch 130\n",
            "total loss: 2.1178252696990967, epoch 9, batch 135\n",
            "total loss: 2.7534539699554443, epoch 9, batch 140\n",
            "total loss: 1.2909395694732666, epoch 9, batch 145\n",
            "total loss: 2.2739181518554688, epoch 9, batch 150\n",
            "total loss: 2.2893588542938232, epoch 9, batch 155\n",
            "total loss: 1.1321239471435547, epoch 9, batch 160\n",
            "total loss: 1.2797558307647705, epoch 9, batch 165\n",
            "total loss: 0.9160667061805725, epoch 9, batch 170\n",
            "total loss: 1.0059658288955688, epoch 9, batch 175\n",
            "total loss: 1.0178557634353638, epoch 9, batch 180\n",
            "total loss: 0.5497552752494812, epoch 9, batch 185\n",
            "total loss: 0.7892986536026001, epoch 9, batch 190\n",
            "total loss: 1.8463777303695679, epoch 9, batch 195\n",
            "total loss: 1.817273497581482, epoch 10, batch 5\n",
            "total loss: 3.035344362258911, epoch 10, batch 10\n",
            "total loss: 2.017564058303833, epoch 10, batch 15\n",
            "total loss: 2.327449083328247, epoch 10, batch 20\n",
            "total loss: 2.3454835414886475, epoch 10, batch 25\n",
            "total loss: 2.191932439804077, epoch 10, batch 30\n",
            "total loss: 2.5497190952301025, epoch 10, batch 35\n",
            "total loss: 1.7001103162765503, epoch 10, batch 40\n",
            "total loss: 1.5331960916519165, epoch 10, batch 45\n",
            "total loss: 1.0857053995132446, epoch 10, batch 50\n",
            "total loss: 1.2939939498901367, epoch 10, batch 55\n",
            "total loss: 0.8903396725654602, epoch 10, batch 60\n",
            "total loss: 1.4756250381469727, epoch 10, batch 65\n",
            "total loss: 1.2939485311508179, epoch 10, batch 70\n",
            "total loss: 1.260446548461914, epoch 10, batch 75\n",
            "total loss: 1.5707963705062866, epoch 10, batch 80\n",
            "total loss: 1.5049091577529907, epoch 10, batch 85\n",
            "total loss: 1.7829619646072388, epoch 10, batch 90\n",
            "total loss: 2.0598363876342773, epoch 10, batch 95\n",
            "total loss: 1.701623558998108, epoch 10, batch 100\n",
            "total loss: 2.223163366317749, epoch 10, batch 105\n",
            "total loss: 1.5507351160049438, epoch 10, batch 110\n",
            "total loss: 2.2316508293151855, epoch 10, batch 115\n",
            "total loss: 1.864611029624939, epoch 10, batch 120\n",
            "total loss: 1.2383902072906494, epoch 10, batch 125\n",
            "total loss: 2.5582828521728516, epoch 10, batch 130\n",
            "total loss: 2.005157232284546, epoch 10, batch 135\n",
            "total loss: 2.5877575874328613, epoch 10, batch 140\n",
            "total loss: 1.22219979763031, epoch 10, batch 145\n",
            "total loss: 2.164769411087036, epoch 10, batch 150\n",
            "total loss: 2.1506142616271973, epoch 10, batch 155\n",
            "total loss: 1.0223807096481323, epoch 10, batch 160\n",
            "total loss: 1.0786986351013184, epoch 10, batch 165\n",
            "total loss: 0.8390094041824341, epoch 10, batch 170\n",
            "total loss: 0.9590029120445251, epoch 10, batch 175\n",
            "total loss: 0.8930230140686035, epoch 10, batch 180\n",
            "total loss: 0.44105497002601624, epoch 10, batch 185\n",
            "total loss: 0.7143831253051758, epoch 10, batch 190\n",
            "total loss: 1.7005023956298828, epoch 10, batch 195\n",
            "Saving encoder weights locally\n",
            "Saving decoder weights locally\n",
            "Saved model weights locally\n",
            "Saving model with wandb\n",
            "Executing mocked noop symlink with arguments ('/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45/models/saved/baseline/encoder.h5', './reports/wandb/run-20200505_072800-yn2vhb36/encoder.h5')\n",
            "Executing mocked noop symlink with arguments ('/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45/models/saved/baseline/decoder.h5', './reports/wandb/run-20200505_072800-yn2vhb36/decoder.h5')\n",
            "Done saving model\n",
            "Test inputs:  [[   8   15  486   10    7    5  137 4043    4  140    3 1674  259   48\n",
            "    25    4   58    2    5  137 4043    4  140  132    3    7   17  486\n",
            "     2    5 1144  609 2062    3  486    2    5    9    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]\n",
            " [   8   13   42    3    7    6 1144  609 2062    3    7    2    2    5\n",
            "     9    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
            "     0    0    0    0]]\n",
            "Predictions:  [[  4  37 750 178   3   3   3  32   3   3   3   3   3   3   3   3]\n",
            " [  4  65   3   3   3   3   3   3   3   3   3   3   3   3   3   3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqKdkHFmUE0e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# using the %run magic command doesn't work as expected\n",
        "# for some reason the GPU Colab instance hangs when trying to read a 50 MB .h5 file\n",
        "\n",
        "# %run src/pipelines/baseline.py \\\n",
        "#   --file_data_raw ../data/interim/method-names-rich/elasticsearch.csv \\\n",
        "#   --file_model_dir models/saved/baseline/ \\\n",
        "#   --dir_preprocessed_data ../data/interim/preprocessed/ \\\n",
        "#   --max_input_length 200 \\\n",
        "#   --max_output_length 8 \\\n",
        "#   --input_vocab_size 20000 \\\n",
        "#   --input_embedding_dim 128 \\\n",
        "#   --output_vocab_size 6000 \\\n",
        "#   --output_embedding_dim 128 \\\n",
        "#   --latent_dim 512 \\\n",
        "#   --learning_rate 0.0001 \\\n",
        "#   --epochs 1 \\\n",
        "#   --batch_size 256 \\\n",
        "#   --random_seed 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-dJLq6QuWrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpKoQs1VuMQI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "817b68cc-0a4a-41ff-eb99-1bb77f206ddf"
      },
      "source": [
        "os.symlink(\n",
        "    '/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45/models/saved/baseline/encoder.h5',\n",
        "    './reports/wandb/run-20200505_065418-17sjamuy/encoder.h5'\n",
        ")"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Executing mocked noop symlink with arguments ('/content/gdrive/My Drive/src/identifier-suggestion-2020-05-05T06-53-45/models/saved/baseline/encoder.h5', './reports/wandb/run-20200505_065418-17sjamuy/encoder.h5')\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}