{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions\n",
    "\n",
    "1. [ ] Define input and output\n",
    " - Input: sequence of code tokens, where token to predict is <UNK>\n",
    " - Output: a list of predicted tokens, sorted in descending order of probability\n",
    "1. [ ] Define evaluation metric\n",
    " - Should be rank-aware, e.g. MRR, MAP, NDCG.\n",
    " - The target token is split into subtokens and the overlap between the predicted token and the target token at subtoken level is evaluated. This can be done with an F1 score.\n",
    "    - For example, if `transformSearchResponse` is the target token, its subtokens are `transform`, `search` and `response`. If the predicted token is `modifySearchResponse`, then the overlap is 2 subtokens out of 3.\n",
    "    - [ ] Should we account for the order of the subtokens? Most probably, yes.\n",
    "    ```\n",
    "    Precision = TP / (TP + FP) = #overlapping-predicted / (#overlapping-predicted + #nonoverlapping-predicted)\n",
    "    Recall = TP / (TP + FN) = #overlapping-predicted / (#overlapping-predicted + #nonoverlapping-required)\n",
    "    F1 = 2 * P * R / (P + R)\n",
    "    ```\n",
    " - The F1 approach is inspired by SQuAD and \"Suggesting accurate method and class names\" by Allamanis et al.\n",
    "\n",
    "## Execution Tasks\n",
    "\n",
    "1. [ ] Gather Data\n",
    "1. [ ] Analyze Data\n",
    "1. [ ] Implement an algorithm\n",
    "1. [ ] Create an evaluation loop\n",
    "1. [ ] Expose parameters of the algorithm\n",
    "1. [ ] Make experiments\n",
    "1. [ ] Document the experiments - Hypothesis, Data, Setup, Evaluation, Algorithm, Experiments, Conclusion, Further Steps\n",
    "\n",
    "\n",
    "\n",
    "## Discussion\n",
    "it isn't as simple as, jsut average some word embeddings\n",
    "it is easy to average the embeddings if you need to predict a word\n",
    "but i have to predict a an unknown amount of subtokens\n",
    "\n",
    "well, why don't we try to predict subtoken at a time\n",
    "but what type should it be?\n",
    "well, we can split all tokens into subtokens and count the PoS occurrences\n",
    "so that we know a few patterns upfront\n",
    "and use these patterns to fill in the subtokens with averaged word embeddings\n",
    "similar to the context we have, but filtered according to the PoS tag\n",
    "this is an interesting idea, because we do suggestion at the subtoken level\n",
    "i like this idea and we can try it\n",
    "\n",
    "of course the other idea is to use source code embeddings directly\n",
    "but they have to be learned on our source code base\n",
    "and this is a separate problem\n",
    "which involves learning a model\n",
    "which is what we try to avoid with our simplistic baseline\n",
    "we are just exploring ideas\n",
    "a baseline without learning might be a failure\n",
    "but the ideas we try and pick up during the design and experimentation are what is most valuable\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_camel_case(token):\n",
    "#     TODO: implement me\n",
    "    return token\n",
    "\n",
    "def get_subtokens(token):\n",
    "    return split_by_camel_case(token)\n",
    "\n",
    "def compute_f1(target_token, predicted_token):\n",
    "    target_subtokens = get_subtokens(target_token)\n",
    "    predicted_subtokens = get_subtokens(predicted_token)\n",
    "    overlapping = Counter(target_subtokens) & Counter(predicted_subtokens)\n",
    "    overlapping_count = sum(overlapping.values())\n",
    "    \n",
    "    precision = 1.0 * overlapping_count / len(predicted_subtokens)\n",
    "    recall = 1.0 * overlapping_count / len(target_subtokens)\n",
    "    f1 = (2.0 * precision * recall) / (precision + recall)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_f1(['transform', 'search', 'response'], ['modify', 'search', 'response', 'data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}