{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import sys\n",
    "import re\n",
    "import javalang\n",
    "import json\n",
    "import os\n",
    "\n",
    "from itertools import chain, takewhile\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.seq2seq_attention import Decoder, Seq2SeqAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/interim/preprocessed/input_vocab_index.json') as f:\n",
    "    input_vocab_index = json.load(f)\n",
    "with open('../data/interim/preprocessed/output_vocab_index.json') as f:\n",
    "    output_vocab_index = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restoring model config\n",
      "Loaded model config:  {'checkpoint_dir': 'models/checkpoints/baseline/', 'max_input_seq_length': 200, 'max_output_seq_length': 8, 'input_vocab_size': 20000, 'output_vocab_size': 6000, 'input_embedding_dim': 128, 'output_embedding_dim': 128, 'rnn_units': 512, 'dense_units': 512, 'batch_size': 256, 'eval_averaging': 'macro'}\n",
      "Restored from ../models/checkpoints/baseline/ckpt-14\n",
      "Done restoring model\n"
     ]
    }
   ],
   "source": [
    "model = Seq2SeqAttention.restore(\n",
    "    '../models/checkpoints/baseline/',\n",
    "    input_vocab_index = input_vocab_index,\n",
    "    output_vocab_index = output_vocab_index,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "EncoderEmbedding (Embedding) multiple                  2560000   \n",
      "_________________________________________________________________\n",
      "EncoderLSTM (LSTM)           multiple                  1312768   \n",
      "=================================================================\n",
      "Total params: 3,872,768\n",
      "Trainable params: 3,872,768\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "DecoderEmbedding (Embedding) multiple                  768000    \n",
      "_________________________________________________________________\n",
      "DenseOutput (Dense)          multiple                  3078000   \n",
      "_________________________________________________________________\n",
      "DecoderLSTMCell (LSTMCell)   multiple                  2361344   \n",
      "_________________________________________________________________\n",
      "LuongAttention (LuongAttenti multiple                  262144    \n",
      "_________________________________________________________________\n",
      "attention_wrapper (Attention multiple                  3147776   \n",
      "_________________________________________________________________\n",
      "basic_decoder (BasicDecoder) multiple                  6225776   \n",
      "=================================================================\n",
      "Total params: 6,993,776\n",
      "Trainable params: 6,993,776\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c39c01d0779f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "model.decoder.embedding.variables[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "    optimizer=model.optimizer,\n",
    "    encoder=model.encoder,\n",
    "    decoder=model.decoder\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./training_checkpoints/ckpt-3'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fcf5381b240>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:  { System.out.println(\"hello world\"); }\n",
      "Tokenized text:  ['{', 'System', '.', 'out', '.', 'println', '(', '<STR>', ')', ';', '}']\n",
      "Encoded tokens:  [  8 507   4 109   4 868   3   7   2   5   9]\n",
      "Raw prediction:  tf.Tensor(\n",
      "[1685  800 1274 1274 3428 3428 3078 1553 3078 1553 1553 1906 1906 2195\n",
      " 3417 3417], shape=(16,), dtype=int32)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-13c7a106dcf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{ System.out.println(\"hello world\"); }'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/source/identifier-suggestion/src/models/seq2seq_attention.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_text)\u001b[0m\n\u001b[1;32m    736\u001b[0m         predicted_text = ''.join([\n\u001b[1;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_output_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<OOV>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_raw_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         ])\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/src/models/seq2seq_attention.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    736\u001b[0m         predicted_text = ''.join([\n\u001b[1;32m    737\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreverse_output_index\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'<OOV>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclean_raw_prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    739\u001b[0m         ])\n\u001b[1;32m    740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__hash__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    703\u001b[0m     if (Tensor._USE_EQUALITY and executing_eagerly_outside_functions() and\n\u001b[1;32m    704\u001b[0m         (g is None or g._building_function)):  # pylint: disable=protected-access\n\u001b[0;32m--> 705\u001b[0;31m       raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\n\u001b[0m\u001b[1;32m    706\u001b[0m                       \"Instead, use tensor.experimental_ref() as the key.\")\n\u001b[1;32m    707\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key."
     ]
    }
   ],
   "source": [
    "model.predict('{ System.out.println(\"hello world\"); }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'asdf asdf'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.constant('asdf asdf').numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "\n",
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_vocab_size,\n",
    "        embedding_dims,\n",
    "        rnn_units,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):        \n",
    "        super(Encoder, self).__init__(self, args, kwargs)\n",
    "        self.input_vocab_size = input_vocab_size\n",
    "        self.embedding_dims = embedding_dims\n",
    "        self.rnn_units = rnn_units\n",
    "        \n",
    "        self.encoder_embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=self.input_vocab_size,\n",
    "            output_dim=self.embedding_dims,\n",
    "        )\n",
    "\n",
    "        self.encoder_rnn = tf.keras.layers.LSTM(\n",
    "            self.rnn_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True\n",
    "            # TODO: what initializer?\n",
    "        )\n",
    "    \n",
    "\n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(None, None), dtype=tf.int32)])\n",
    "    def call(self, input_batch):\n",
    "        # TODO: control the initial cell state with methods exposed by the Encoder\n",
    "        encoder_initial_cell_state = [\n",
    "            tf.zeros((BATCH_SIZE, self.rnn_units)),\n",
    "            tf.zeros((BATCH_SIZE, self.rnn_units)),\n",
    "        ]\n",
    "\n",
    "        embeddings = self.encoder_embedding(input_batch)\n",
    "\n",
    "        a, a_tx, c_tx = self.encoder_rnn(\n",
    "            embeddings,\n",
    "            initial_state=encoder_initial_cell_state\n",
    "        )\n",
    "\n",
    "        print(a.shape)\n",
    "        \n",
    "        return a, a_tx, c_tx\n",
    "\n",
    "    def get_config(self):\n",
    "        return {\n",
    "            'input_vocab_size': self.input_vocab_size,\n",
    "            'embedding_dims': self.embedding_dims,\n",
    "            'rnn_units': self.rnn_units,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "        input_vocab_size=20000,\n",
    "        embedding_dims=256,\n",
    "        rnn_units=1024,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(64, 200), dtype=int32, numpy=\n",
       "array([[1793, 8080, 8292, ..., 4528, 2929, 7394],\n",
       "       [2467, 6730, 2985, ..., 4746, 3230, 5508],\n",
       "       [5469,  481, 9473, ...,  947, 5752, 6780],\n",
       "       ...,\n",
       "       [6781, 7268, 7105, ..., 1643, 5666, 3238],\n",
       "       [6416, 7840, 2283, ...,  535, 5284, 2563],\n",
       "       [2484, 2288, 5939, ..., 4810,  179, 1575]], dtype=int32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_input = tf.random.uniform(shape=(64, 200), dtype=tf.int32, minval=0, maxval=10000)\n",
    "example_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, None, 1024)\n",
      "(64, None, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 200, 1024), dtype=float32, numpy=\n",
       " array([[[ 7.6588843e-04,  1.7727673e-03,  6.3451291e-03, ...,\n",
       "           9.8098349e-04,  4.2077182e-03, -3.2043707e-05],\n",
       "         [-1.8100429e-03,  4.0911017e-03,  7.3657539e-03, ...,\n",
       "           1.2662027e-03,  6.1758989e-03,  2.9822553e-03],\n",
       "         [-2.0021806e-04,  6.7549725e-03,  5.8208378e-03, ...,\n",
       "           2.8371280e-03,  8.4218215e-03,  4.5139161e-03],\n",
       "         ...,\n",
       "         [ 5.4292176e-03,  8.9307496e-04,  8.2179834e-04, ...,\n",
       "          -1.2783856e-03, -6.3484622e-04, -8.7233740e-05],\n",
       "         [ 8.4837229e-05,  3.9370186e-03, -6.9826067e-04, ...,\n",
       "           2.2946780e-03, -5.1997550e-04, -5.1467479e-03],\n",
       "         [-2.4949033e-03,  5.4845545e-03,  6.1233575e-04, ...,\n",
       "          -3.0808244e-03, -2.2178921e-03, -3.3016142e-03]],\n",
       " \n",
       "        [[ 7.1628549e-04,  4.3132463e-03, -1.5510898e-03, ...,\n",
       "           1.0144889e-03, -2.1907857e-03,  6.1074283e-04],\n",
       "         [ 2.9716760e-04,  3.5128277e-03, -1.3939792e-03, ...,\n",
       "          -2.3609579e-03, -7.8922872e-05, -2.4301947e-04],\n",
       "         [ 4.4581695e-03, -3.8031096e-04, -1.1211701e-03, ...,\n",
       "          -2.2765265e-03, -8.5122348e-04,  1.9484507e-04],\n",
       "         ...,\n",
       "         [ 4.3980801e-03, -3.9498378e-03,  1.2484863e-03, ...,\n",
       "          -5.2321348e-03,  4.2505373e-04, -2.3491515e-03],\n",
       "         [-5.4746220e-04, -4.0799825e-04,  2.1674370e-03, ...,\n",
       "          -3.6537622e-03, -6.6525289e-03, -4.1714401e-04],\n",
       "         [ 3.1673156e-03, -7.5548748e-03, -1.8998246e-03, ...,\n",
       "           2.0911451e-03, -3.4624974e-03, -1.8867269e-03]],\n",
       " \n",
       "        [[-1.4849470e-04, -2.1289901e-03, -9.2989166e-04, ...,\n",
       "           1.3940965e-03, -2.5135791e-03,  4.0751132e-03],\n",
       "         [-3.8997445e-03,  7.5063610e-04,  2.0903950e-03, ...,\n",
       "           2.2196763e-03, -1.4376987e-03,  4.4376957e-03],\n",
       "         [-2.7078257e-03,  3.2831570e-03,  2.9993802e-03, ...,\n",
       "           4.3952079e-03,  1.3986373e-03, -2.7972111e-04],\n",
       "         ...,\n",
       "         [ 3.3781424e-03, -5.5275817e-04, -4.5641966e-04, ...,\n",
       "          -1.3021261e-03, -4.4036391e-03,  2.3370190e-03],\n",
       "         [-9.9479035e-04, -2.6050913e-03,  2.4541171e-04, ...,\n",
       "           5.1239673e-03, -1.4366012e-03, -7.4779215e-05],\n",
       "         [-4.1754423e-03, -3.9294241e-03, -1.9379400e-04, ...,\n",
       "           7.5077554e-03, -3.1947489e-03, -6.7072390e-03]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 5.6007528e-04,  3.6955180e-03, -8.9876744e-04, ...,\n",
       "          -2.5672570e-03,  2.3863250e-03,  5.8499211e-03],\n",
       "         [-8.2679698e-04,  1.6027719e-03, -3.3561098e-03, ...,\n",
       "          -8.8660180e-04,  3.4883416e-03, -4.1184231e-04],\n",
       "         [-1.7828023e-03,  1.8379994e-03, -4.3037971e-03, ...,\n",
       "           4.7435923e-03,  5.5424958e-03, -1.2799418e-03],\n",
       "         ...,\n",
       "         [ 2.3308278e-04,  2.3460721e-03,  3.6060854e-04, ...,\n",
       "           6.6950927e-03,  4.5534070e-03,  2.3247518e-03],\n",
       "         [-2.2821904e-03,  3.7831047e-03, -1.5923040e-03, ...,\n",
       "           1.0175617e-02,  1.1358138e-03,  7.3683034e-03],\n",
       "         [ 2.2646264e-04,  5.4739239e-03,  8.4914704e-05, ...,\n",
       "           7.0546735e-03,  3.6055574e-03,  4.4705919e-03]],\n",
       " \n",
       "        [[-2.1508394e-03, -1.3753867e-03,  2.2356960e-03, ...,\n",
       "          -1.8058331e-03, -1.2163178e-03,  2.9264048e-03],\n",
       "         [-7.5738726e-04, -1.0465947e-04, -3.3071619e-03, ...,\n",
       "          -5.5429381e-03, -2.1352062e-03,  1.4795037e-03],\n",
       "         [-1.1731242e-03,  3.5592329e-03, -9.7433906e-03, ...,\n",
       "          -9.2680193e-03,  1.7001501e-03,  5.1607862e-03],\n",
       "         ...,\n",
       "         [-2.6822395e-03,  2.7038783e-03,  5.8007664e-03, ...,\n",
       "           6.6057211e-03,  5.8238511e-03,  6.2401496e-06],\n",
       "         [-1.5262143e-03,  3.8578550e-03,  5.3167799e-03, ...,\n",
       "           1.2517887e-03,  3.0429121e-03, -1.2351102e-03],\n",
       "         [ 1.3152474e-03,  4.1609448e-03,  7.1148835e-03, ...,\n",
       "          -1.2782443e-03,  2.5579214e-04,  6.3716194e-05]],\n",
       " \n",
       "        [[-2.2337434e-03,  3.0242316e-03,  1.1767398e-03, ...,\n",
       "          -5.1415316e-04, -8.7889680e-04,  2.5827717e-03],\n",
       "         [ 2.1326123e-03,  3.8180347e-03, -2.1657984e-04, ...,\n",
       "           2.2741805e-03, -2.5516486e-04,  2.0178617e-03],\n",
       "         [-3.4387000e-03,  3.2177705e-03, -2.1809139e-03, ...,\n",
       "           2.5573201e-03,  1.5011212e-03,  2.3025186e-03],\n",
       "         ...,\n",
       "         [-7.8465929e-03,  3.2834986e-03, -2.0413494e-03, ...,\n",
       "          -3.3457929e-03,  3.4504803e-03, -1.9636645e-03],\n",
       "         [-5.3898492e-03, -1.6524927e-03, -3.8983324e-04, ...,\n",
       "          -4.5594093e-04,  2.1016269e-03, -2.1945882e-04],\n",
       "         [-2.9594305e-03, -3.8420365e-04, -1.5137016e-03, ...,\n",
       "          -8.5994945e-04,  2.2640326e-03, -3.1321722e-03]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       " array([[-2.4949033e-03,  5.4845545e-03,  6.1233575e-04, ...,\n",
       "         -3.0808244e-03, -2.2178921e-03, -3.3016142e-03],\n",
       "        [ 3.1673156e-03, -7.5548748e-03, -1.8998246e-03, ...,\n",
       "          2.0911451e-03, -3.4624974e-03, -1.8867269e-03],\n",
       "        [-4.1754423e-03, -3.9294241e-03, -1.9379400e-04, ...,\n",
       "          7.5077554e-03, -3.1947489e-03, -6.7072390e-03],\n",
       "        ...,\n",
       "        [ 2.2646264e-04,  5.4739239e-03,  8.4914704e-05, ...,\n",
       "          7.0546735e-03,  3.6055574e-03,  4.4705919e-03],\n",
       "        [ 1.3152474e-03,  4.1609448e-03,  7.1148835e-03, ...,\n",
       "         -1.2782443e-03,  2.5579214e-04,  6.3716194e-05],\n",
       "        [-2.9594305e-03, -3.8420365e-04, -1.5137016e-03, ...,\n",
       "         -8.5994945e-04,  2.2640326e-03, -3.1321722e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       " array([[-0.00498261,  0.01090318,  0.00122948, ..., -0.00618665,\n",
       "         -0.00441309, -0.00660571],\n",
       "        [ 0.00630651, -0.01514673, -0.00379515, ...,  0.00417103,\n",
       "         -0.00694412, -0.0037895 ],\n",
       "        [-0.00834098, -0.00783709, -0.000392  , ...,  0.01500955,\n",
       "         -0.00640355, -0.01346366],\n",
       "        ...,\n",
       "        [ 0.00044913,  0.01092668,  0.00016963, ...,  0.01413186,\n",
       "          0.00718304,  0.0088447 ],\n",
       "        [ 0.0026295 ,  0.0083401 ,  0.01429805, ..., -0.00255691,\n",
       "          0.00051065,  0.00012742],\n",
       "        [-0.00589843, -0.00076633, -0.00302909, ..., -0.00172193,\n",
       "          0.00452295, -0.0062747 ]], dtype=float32)>)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      multiple                  5120000   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                multiple                  5246976   \n",
      "=================================================================\n",
      "Total params: 10,366,976\n",
      "Trainable params: 10,366,976\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(tf.Module):\n",
    "    def __init__(self, encoder):\n",
    "        self.encoder = encoder\n",
    "    \n",
    "    @tf.function(input_signature=[tf.TensorSpec(shape=(), dtype=tf.int32)])\n",
    "    def predict(self, input):\n",
    "        return input + 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, None, 1024)\n",
      "(64, None, 1024)\n"
     ]
    }
   ],
   "source": [
    "seq2seq.encoder._set_inputs(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, None, 1024)\n",
      "(64, None, 1024)\n",
      "(64, None, 1024)\n",
      "(64, None, 1024)\n",
      "(64, None, 1024)\n",
      "INFO:tensorflow:Assets written to: saved/assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(seq2seq, 'saved/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.saved_model.load('saved/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=43>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.predict(tf.constant(1, dtype=tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(64, 200, 1024), dtype=float32, numpy=\n",
       " array([[[-1.07136206e-03,  1.64062670e-03,  5.75630320e-03, ...,\n",
       "          -6.56103366e-04, -1.24000115e-04,  6.12761127e-04],\n",
       "         [-2.56629847e-03,  5.95884398e-03,  3.83697334e-03, ...,\n",
       "          -1.36840157e-03, -6.94576069e-04, -1.08752726e-03],\n",
       "         [-5.19726705e-03,  6.24632603e-03,  1.56510156e-03, ...,\n",
       "           2.29577976e-03,  1.35047827e-03, -2.55882205e-03],\n",
       "         ...,\n",
       "         [-9.18015186e-03,  8.08782177e-04, -1.32281415e-03, ...,\n",
       "           1.65855349e-03,  4.27730707e-03,  3.92429112e-03],\n",
       "         [-5.29159745e-03,  4.56034858e-03, -2.97900848e-03, ...,\n",
       "           4.09107655e-03,  1.02088309e-03,  1.06613780e-03],\n",
       "         [-5.54750022e-03,  2.66223447e-03,  2.05846052e-04, ...,\n",
       "          -7.14774069e-04,  8.28324351e-04, -5.85777743e-04]],\n",
       " \n",
       "        [[ 2.47884751e-03, -4.87157289e-04, -1.88332621e-03, ...,\n",
       "          -2.56122951e-03, -6.05700817e-03, -3.03794374e-03],\n",
       "         [ 1.33349979e-03,  2.63747550e-03, -2.69316463e-03, ...,\n",
       "           1.45808724e-03, -4.11964674e-03,  7.14949623e-04],\n",
       "         [ 2.83501856e-03,  1.42872054e-03, -5.39582549e-03, ...,\n",
       "           3.25461105e-03, -5.14501287e-03, -2.53292802e-03],\n",
       "         ...,\n",
       "         [ 9.36818717e-04,  5.21579245e-03, -4.28783102e-03, ...,\n",
       "           5.01431711e-03, -1.94153446e-03, -3.21357953e-03],\n",
       "         [-3.42134910e-04,  2.57917331e-03,  6.40210463e-04, ...,\n",
       "           3.01319500e-03,  3.29920859e-03,  1.47064184e-05],\n",
       "         [-4.57205286e-04,  1.09631440e-03, -5.21203922e-03, ...,\n",
       "           2.37668073e-03,  1.02495821e-03, -9.43627150e-04]],\n",
       " \n",
       "        [[-7.16640207e-04, -3.59184016e-03, -1.44580926e-03, ...,\n",
       "           8.20721849e-04,  1.97867071e-03,  2.01862538e-03],\n",
       "         [-1.63898454e-03, -4.87976987e-03, -3.63051798e-03, ...,\n",
       "           7.93490000e-03, -2.05720658e-03,  4.63112537e-03],\n",
       "         [ 4.74812143e-04, -3.28336633e-03,  1.04575988e-03, ...,\n",
       "           1.28708435e-02, -2.32455740e-03,  3.54676927e-03],\n",
       "         ...,\n",
       "         [ 6.45652926e-03, -3.91916977e-03,  8.37456156e-03, ...,\n",
       "          -2.38127448e-03, -2.62968871e-03, -4.62969439e-03],\n",
       "         [ 6.08596113e-03, -2.30268692e-03,  7.36086676e-03, ...,\n",
       "           1.87235337e-03, -2.73996685e-03, -2.99824774e-03],\n",
       "         [ 4.88325208e-03, -6.20514434e-03,  8.70461762e-03, ...,\n",
       "           1.44832395e-03, -1.05945754e-03, -3.85415799e-04]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[ 1.01248047e-03,  2.91920779e-03,  1.37166004e-03, ...,\n",
       "          -2.36990652e-03, -1.59456872e-03, -3.01067397e-04],\n",
       "         [ 2.11517280e-03, -8.77005863e-04,  1.29294582e-03, ...,\n",
       "           1.46340528e-06,  4.67257603e-04, -3.34483641e-03],\n",
       "         [ 2.19506444e-03, -3.93231306e-03,  6.71105401e-04, ...,\n",
       "          -9.33073927e-04, -3.61601647e-04, -1.65208534e-03],\n",
       "         ...,\n",
       "         [ 1.92226889e-03,  5.18399198e-03, -4.24257433e-03, ...,\n",
       "          -3.29586584e-03,  3.04540619e-03, -6.49044802e-03],\n",
       "         [ 9.08666290e-03,  2.65530031e-03,  2.89580435e-04, ...,\n",
       "          -3.30735394e-03, -6.00592466e-04, -7.80733861e-03],\n",
       "         [ 6.03454327e-03,  2.59406772e-03,  1.67447689e-03, ...,\n",
       "          -3.71768349e-03, -2.85355514e-03, -7.10010529e-03]],\n",
       " \n",
       "        [[-4.19453776e-04, -3.73288116e-04,  1.79380353e-03, ...,\n",
       "           4.71847132e-03, -2.39008875e-03,  4.78099333e-03],\n",
       "         [-5.61062619e-03, -3.89859616e-03,  6.89613540e-03, ...,\n",
       "           4.43965476e-03, -4.33000503e-03,  6.45571761e-03],\n",
       "         [-2.11128779e-03, -1.01480354e-03,  8.62148590e-03, ...,\n",
       "           3.37682688e-03, -4.17679921e-03,  2.01493967e-03],\n",
       "         ...,\n",
       "         [-2.23723328e-04,  6.07687188e-03,  6.58493675e-03, ...,\n",
       "          -8.87355942e-04,  3.62383807e-03, -5.94818173e-03],\n",
       "         [-2.70973472e-03,  5.00078453e-03,  2.68765399e-03, ...,\n",
       "          -2.01193709e-03,  1.40625960e-03, -7.42915459e-03],\n",
       "         [ 2.42381403e-03,  5.61549561e-03, -2.52119568e-03, ...,\n",
       "          -1.13692763e-03, -7.52270164e-04,  2.52242608e-05]],\n",
       " \n",
       "        [[-2.60440953e-04,  4.00735531e-03,  5.96762681e-03, ...,\n",
       "          -7.42215198e-05,  3.29242600e-03, -5.94593876e-04],\n",
       "         [ 9.10047849e-04,  7.25015765e-03,  2.31159781e-03, ...,\n",
       "           3.20687628e-04,  6.32917834e-03,  3.03809717e-03],\n",
       "         [ 9.73297691e-04,  4.82201809e-03,  4.33128607e-03, ...,\n",
       "           7.26744672e-03,  1.18967728e-03,  6.13248776e-05],\n",
       "         ...,\n",
       "         [-6.11575274e-03,  1.00909511e-03,  4.71861381e-03, ...,\n",
       "          -1.68993080e-03,  2.46637804e-03,  5.67428395e-03],\n",
       "         [ 6.63839281e-04,  3.53279128e-03,  3.10909003e-03, ...,\n",
       "          -2.95974850e-03,  4.27294755e-03,  2.37345160e-03],\n",
       "         [ 2.93239043e-03,  4.80988994e-03,  6.42668083e-03, ...,\n",
       "          -4.87051113e-03,  2.51375558e-03, -3.65464552e-03]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       " array([[-5.5475002e-03,  2.6622345e-03,  2.0584605e-04, ...,\n",
       "         -7.1477407e-04,  8.2832435e-04, -5.8577774e-04],\n",
       "        [-4.5720529e-04,  1.0963144e-03, -5.2120392e-03, ...,\n",
       "          2.3766807e-03,  1.0249582e-03, -9.4362715e-04],\n",
       "        [ 4.8832521e-03, -6.2051443e-03,  8.7046176e-03, ...,\n",
       "          1.4483240e-03, -1.0594575e-03, -3.8541580e-04],\n",
       "        ...,\n",
       "        [ 6.0345433e-03,  2.5940677e-03,  1.6744769e-03, ...,\n",
       "         -3.7176835e-03, -2.8535551e-03, -7.1001053e-03],\n",
       "        [ 2.4238140e-03,  5.6154956e-03, -2.5211957e-03, ...,\n",
       "         -1.1369276e-03, -7.5227016e-04,  2.5224261e-05],\n",
       "        [ 2.9323904e-03,  4.8098899e-03,  6.4266808e-03, ...,\n",
       "         -4.8705111e-03,  2.5137556e-03, -3.6546455e-03]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(64, 1024), dtype=float32, numpy=\n",
       " array([[-1.1129605e-02,  5.3234836e-03,  4.1092606e-04, ...,\n",
       "         -1.4321082e-03,  1.6541074e-03, -1.1683940e-03],\n",
       "        [-9.2283497e-04,  2.1728873e-03, -1.0429835e-02, ...,\n",
       "          4.7404687e-03,  2.0635775e-03, -1.8881236e-03],\n",
       "        [ 9.6629523e-03, -1.2425492e-02,  1.7497879e-02, ...,\n",
       "          2.8987015e-03, -2.1274872e-03, -7.6765707e-04],\n",
       "        ...,\n",
       "        [ 1.2077856e-02,  5.1996205e-03,  3.3427442e-03, ...,\n",
       "         -7.3887613e-03, -5.7093077e-03, -1.4120292e-02],\n",
       "        [ 4.8258994e-03,  1.1252411e-02, -5.0164871e-03, ...,\n",
       "         -2.2640675e-03, -1.5064087e-03,  5.0690956e-05],\n",
       "        [ 5.8979737e-03,  9.6799899e-03,  1.2945906e-02, ...,\n",
       "         -9.6838530e-03,  4.9881348e-03, -7.3609482e-03]], dtype=float32)>)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded.encoder(example_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_output_seq_length,\n",
    "        output_vocab_size,\n",
    "        embedding_dims,\n",
    "        rnn_units,\n",
    "        dense_units,\n",
    "        batch_size,\n",
    "        *args,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        super().__init__(self, args, kwargs)\n",
    "\n",
    "        self.config = {\n",
    "            'max_output_seq_length': max_output_seq_length,\n",
    "            'output_vocab_size': output_vocab_size,\n",
    "            'embedding_dims': embedding_dims,\n",
    "            'rnn_units': rnn_units,\n",
    "            'dense_units': dense_units,\n",
    "            'batch_size': batch_size,\n",
    "        }\n",
    "\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.embedding = tf.keras.layers.Embedding(\n",
    "            input_dim=self.config['output_vocab_size'],\n",
    "            output_dim=self.config['embedding_dims'],\n",
    "            name='DecoderEmbedding'\n",
    "        )\n",
    "\n",
    "        # TODO: why isn't the activation softmax?\n",
    "        self.dense_layer = tf.keras.layers.Dense(\n",
    "            self.config['output_vocab_size'],\n",
    "            name='DenseOutput'\n",
    "        )\n",
    "\n",
    "        self.decoder_rnn_cell = tf.keras.layers.LSTMCell(\n",
    "            self.config['rnn_units'],\n",
    "            name='DecoderLSTMCell'\n",
    "        )\n",
    "\n",
    "        # TODO: why prefer Luong over tfa.seq2seq.BahdanauAttention or vice-versa?\n",
    "        self.attention_mechanism = tfa.seq2seq.LuongAttention(\n",
    "            self.config['dense_units'],\n",
    "            memory = None,\n",
    "            memory_sequence_length = self.config['batch_size'] * [self.config['max_output_seq_length']]\n",
    "        )\n",
    "\n",
    "        self.rnn_cell = tfa.seq2seq.AttentionWrapper(\n",
    "            self.decoder_rnn_cell,\n",
    "            self.attention_mechanism,\n",
    "            attention_layer_size=self.config['dense_units'],\n",
    "        )\n",
    "\n",
    "        # TODO: isn't this sampler only for training? what if we need to pass a sampler for Beam Search?\n",
    "        self.sampler = tfa.seq2seq.sampler.TrainingSampler()\n",
    "\n",
    "        self.decoder = tfa.seq2seq.BasicDecoder(\n",
    "            self.rnn_cell,\n",
    "            sampler=self.sampler,\n",
    "            output_layer=self.dense_layer,\n",
    "        )\n",
    "\n",
    "        super().build(input_shape)\n",
    "\n",
    "\n",
    "    def call(self, input_batch):\n",
    "#         # set up decoder memory from encoder output\n",
    "        self.attention_mechanism.setup_memory(tf.zeros((\n",
    "            self.config['batch_size'],\n",
    "            200, # input sequence length\n",
    "            self.config['rnn_units'],\n",
    "        ))) # TODO: a\n",
    "\n",
    "        empty_encoder_state = [\n",
    "            tf.zeros((self.config['batch_size'], self.config['rnn_units'])),\n",
    "            tf.zeros((self.config['batch_size'], self.config['rnn_units'])),\n",
    "        ]\n",
    "\n",
    "        decoder_initial_state = self.build_decoder_initial_state(\n",
    "            self.config['batch_size'], # TODO: this parameter should be known already\n",
    "            # [last step activations, last memory_state] of encoder is passed as input to decoder Network\n",
    "            encoder_state=empty_encoder_state, # TODO: use more appropriate names\n",
    "        )\n",
    "\n",
    "        # ignore hidden state and cell state from decoder RNN\n",
    "        outputs, _, _ = self.decoder(\n",
    "            self.embedding(input_batch),\n",
    "            initial_state=decoder_initial_state,\n",
    "\n",
    "            # TODO: don't we know the BATCH_SIZE already inside the decoder? should we?\n",
    "            # output sequence length - 1 because of teacher forcing\n",
    "            sequence_length=self.config['batch_size'] * [self.config['max_output_seq_length'] - 1]\n",
    "        )\n",
    "\n",
    "        return outputs\n",
    "\n",
    "\n",
    "\n",
    "    def get_config(self):\n",
    "        return self.config\n",
    "\n",
    "\n",
    "    def build_decoder_initial_state(\n",
    "        self,\n",
    "        batch_size,\n",
    "        encoder_state,\n",
    "    ):\n",
    "        decoder_initial_state = self.rnn_cell.get_initial_state(\n",
    "            batch_size=batch_size,\n",
    "            dtype=tf.float32, # TODO: do we need this dtype at all?\n",
    "        )\n",
    "\n",
    "        # TODO: why clone? do we clone the encoder_state? what's going on here?\n",
    "        return decoder_initial_state.clone(cell_state=encoder_state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder= Decoder(\n",
    "            max_output_seq_length=8,\n",
    "            output_vocab_size=10000,\n",
    "            embedding_dims=128,\n",
    "            rnn_units=1024,\n",
    "            dense_units=1024,\n",
    "            batch_size=256,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.build(input_shape=(256, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"decoder_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "DecoderEmbedding (Embedding) multiple                  1280000   \n",
      "_________________________________________________________________\n",
      "DenseOutput (Dense)          multiple                  10250000  \n",
      "_________________________________________________________________\n",
      "DecoderLSTMCell (LSTMCell)   multiple                  8916992   \n",
      "_________________________________________________________________\n",
      "LuongAttention (LuongAttenti multiple                  1048576   \n",
      "_________________________________________________________________\n",
      "attention_wrapper_6 (Attenti multiple                  12062720  \n",
      "_________________________________________________________________\n",
      "basic_decoder_6 (BasicDecode multiple                  22312720  \n",
      "=================================================================\n",
      "Total params: 23,592,720\n",
      "Trainable params: 23,592,720\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-fcdea476b609>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdecoder_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'../models/saved/baseline-300-epochs/decoder.h5'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    144\u001b[0m   if (h5py is not None and (\n\u001b[1;32m    145\u001b[0m       isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[0;32m--> 146\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mhdf5_format\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model_from_hdf5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     model = model_config_lib.model_from_config(model_config,\n",
      "\u001b[0;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "decoder_path = '../models/saved/baseline-300-epochs/decoder.h5'\n",
    "\n",
    "tf.keras.models.load_model(decoder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.train.load_variable(decoder_path, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 tony tony 63418528 May  9 08:53 ../models/saved/baseline-300-epochs/decoder.h5\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../models/saved/baseline-300-epochs/decoder.h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 3, 5], [2, 4, 6]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(None or np.stack([[1, 2], [3, 4], [5, 6]], axis = 1).tolist() or [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(takewhile(lambda index: index != 3, [1, 2, 3, 4, 5, 6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({1: 2, 2: 4, 3: 2}), Counter({2: 1}), Counter({3: 1}))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label =      [1, 2, 3, 2, 3, 3, 1, 2, 2]\n",
    "prediction = [2, 2, 1, 2, 1, 3, 2, 3, 2]\n",
    "\n",
    "tp = Counter(label) & Counter(prediction) # hits\n",
    "fn = Counter(label) - Counter(prediction) # misses\n",
    "fp = Counter(prediction) - Counter(label) # false alarms\n",
    "\n",
    "tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])>,\n",
       " <tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>,\n",
       " <tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 4\n",
    "\n",
    "unique_values, _idx, counts = tf.unique_with_counts(tf.constant(label, dtype=tf.int64))\n",
    "\n",
    "(unique_values, _idx, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts_per_class(sequence, num_classes):\n",
    "    # the sorting is required to ensure that the returned unique values will be in sorted order\n",
    "    unique_values, _idx, counts = tf.unique_with_counts(tf.sort(sequence))\n",
    "\n",
    "    print(unique_values, counts)\n",
    "    \n",
    "    sparse_tensor = tf.SparseTensor(\n",
    "        indices = tf.expand_dims(unique_values, axis = 1),\n",
    "        values = counts,\n",
    "        dense_shape = [num_classes]\n",
    "    )\n",
    "    \n",
    "    return tf.sparse.to_dense(sparse_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = tf.zeros(num_classes, dtype=tf.int32)\n",
    "\n",
    "def non_negative_subtract(a, b):\n",
    "    return tf.math.maximum(\n",
    "        tf.math.subtract(a, b),\n",
    "        zeros\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2, 2, 1, 2, 1, 3, 2, 3, 2], [1, 2, 3, 2, 3, 3, 1, 2, 2])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([2 4 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([2 5 2], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 2, 4, 2], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 1, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 1], dtype=int32)>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_confusion_matrix_tensor(label, prediction, num_classes):\n",
    "    label_counter = get_counts_per_class(label, num_classes = num_classes)\n",
    "    prediction_counter = get_counts_per_class(prediction, num_classes = num_classes)\n",
    "\n",
    "    hits = tf.math.minimum(label_counter, prediction_counter)\n",
    "    false_alarms = non_negative_subtract(prediction_counter, label_counter)\n",
    "    misses = non_negative_subtract(label_counter, prediction_counter)\n",
    "\n",
    "    return hits, false_alarms, misses\n",
    "\n",
    "compute_confusion_matrix_tensor(\n",
    "    label = tf.constant(label, dtype=tf.int64),\n",
    "    prediction = tf.constant(prediction, dtype=tf.int64),\n",
    "    num_classes = 4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([4 8 6], shape=(3,), dtype=int32)\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int64) tf.Tensor([ 4 10  4], shape=(3,), dtype=int32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 4, 8, 4], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 2, 0], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 2], dtype=int32)>)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tp, fp, fn = compute_confusion_matrix_tensor(\n",
    "    label = tf.reshape(tf.constant([label] * 2, dtype=tf.int64), shape = [-1]),\n",
    "    prediction = tf.reshape(tf.constant([prediction] * 2, dtype=tf.int64), shape = [-1]),\n",
    "    num_classes = 4,\n",
    ")\n",
    "\n",
    "tp, fp, fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_divide(a, b):\n",
    "    return tf.math.divide_no_nan(\n",
    "        tf.cast(a, dtype=tf.float32),\n",
    "        tf.cast(b, dtype=tf.float32)\n",
    "    )\n",
    "\n",
    "def compute_metrics(tp, fp, fn):\n",
    "    precision = safe_divide(tp, tp + fp)\n",
    "    recall = safe_divide(tp, tp + fn)\n",
    "    f1 = safe_divide(2 * precision * recall, precision + recall)\n",
    "\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=float32, numpy=0.67222226>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.7>,\n",
       " <tf.Tensor: shape=(), dtype=float32, numpy=0.6666667>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1, precision, recall = tf.math.reduce_mean(\n",
    "    compute_metrics(tp, fp, fn),\n",
    "    axis = 1\n",
    ")\n",
    "\n",
    "f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=float32, numpy=array([0. , 1. , 0.8, 1. ], dtype=float32)>"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.divide_no_nan(tf.cast(tp, dtype=tf.float32), tf.cast(tp + fp, dtype=tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int32, numpy=16>"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.reduce_sum(tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 2, 4, 3], dtype=int32)>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sparse.to_dense(\n",
    "    tf.SparseTensor(\n",
    "        indices = tf.expand_dims(unique_values, axis = 1),\n",
    "        values = counts,\n",
    "        dense_shape = [num_classes]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 0, 0, 0], dtype=int32)>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_tensor = tf.zeros(num_classes, dtype=tf.int32)\n",
    "zero_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 2, 4, 3], dtype=int32)>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_tensor = tf.sparse.to_dense(\n",
    "    tf.SparseTensor(\n",
    "        indices=[[1], [2], [3]],\n",
    "        values=[2, 4, 3],\n",
    "        dense_shape=[4]\n",
    "    )\n",
    ")\n",
    "counts_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 2, 4, 3], dtype=int32)>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.add(zero_tensor, counts_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (3,) must have rank 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 923\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    924\u001b[0m         \u001b[0mnew_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36massert_same_rank\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    977\u001b[0m         raise ValueError(\"Shapes %s and %s must have the same rank\" %\n\u001b[0;32m--> 978\u001b[0;31m                          (self, other))\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (3,) and (None, None) must have the same rank",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m   1007\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1008\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1009\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mmerge_with\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    928\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 929\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shapes %s and %s are not compatible\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    930\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shapes (3,) and (None, None) are not compatible",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-79-05b1b26c65bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mindices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munique_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdense_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/sparse_tensor.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, indices, values, dense_shape)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m     \u001b[0mindices_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m     \u001b[0mvalues_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mdense_shape_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdense_shape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_rank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m   1008\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munknown_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1009\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1010\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1011\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwith_rank_at_least\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (3,) must have rank 2"
     ]
    }
   ],
   "source": [
    "tf.SparseTensor(\n",
    "    indices=tf.cast(unique_values, tf.int64),\n",
    "    values=tf.cast(counts, tf.int64),\n",
    "    dense_shape=[num_classes]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The two structures don't have the same nested structure.\n\nFirst structure: type=DType str=<dtype: 'int32'>\n\nSecond structure: type=UniqueWithCounts str=UniqueWithCounts(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)\n\nMore specifically: Substructure \"type=UniqueWithCounts str=UniqueWithCounts(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)\" is a sequence, while substructure \"type=DType str=<dtype: 'int32'>\" is not\nEntire first structure:\n.\nEntire second structure:\nUniqueWithCounts(y=., idx=., count=.)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    329\u001b[0m     _pywrap_utils.AssertSameStructure(nest1, nest2, check_types,\n\u001b[0;32m--> 330\u001b[0;31m                                       expand_composites)\n\u001b[0m\u001b[1;32m    331\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=DType str=<dtype: 'int32'>\n\nSecond structure: type=UniqueWithCounts str=UniqueWithCounts(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)\n\nMore specifically: Substructure \"type=UniqueWithCounts str=UniqueWithCounts(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)\" is a sequence, while substructure \"type=DType str=<dtype: 'int32'>\" is not",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-32ca203a57d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique_with_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py\u001b[0m in \u001b[0;36mmap_fn\u001b[0;34m(fn, elems, dtype, parallel_iterations, back_prop, swap_memory, infer_shape, name)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0mback_prop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mback_prop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         maximum_iterations=n)\n\u001b[0m\u001b[1;32m    269\u001b[0m     \u001b[0mresults_flat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mr_a\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2712\u001b[0m                                               list(loop_vars))\n\u001b[1;32m   2713\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0mcond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2714\u001b[0;31m         \u001b[0mloop_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2715\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtry_to_pack\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloop_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_basetuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m           \u001b[0mpacked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2703\u001b[0m         cond = lambda i, lv: (  # pylint: disable=g-long-lambda\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2707\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/map_fn.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(i, tas)\u001b[0m\n\u001b[1;32m    256\u001b[0m       \u001b[0mpacked_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_pack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0melem_ta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem_ta\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melems_ta\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m       \u001b[0mpacked_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m       \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massert_same_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m       \u001b[0mflat_fn_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_flatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpacked_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m       \u001b[0mtas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_fn_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36massert_same_structure\u001b[0;34m(nest1, nest2, check_types, expand_composites)\u001b[0m\n\u001b[1;32m    335\u001b[0m                   \u001b[0;34m\"Entire first structure:\\n%s\\n\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m                   \u001b[0;34m\"Entire second structure:\\n%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 337\u001b[0;31m                   % (str(e), str1, str2))\n\u001b[0m\u001b[1;32m    338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The two structures don't have the same nested structure.\n\nFirst structure: type=DType str=<dtype: 'int32'>\n\nSecond structure: type=UniqueWithCounts str=UniqueWithCounts(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)\n\nMore specifically: Substructure \"type=UniqueWithCounts str=UniqueWithCounts(y=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([1, 2, 3], dtype=int32)>, idx=<tf.Tensor: shape=(9,), dtype=int32, numpy=array([0, 1, 2, 1, 2, 2, 0, 1, 1], dtype=int32)>, count=<tf.Tensor: shape=(3,), dtype=int32, numpy=array([2, 4, 3], dtype=int32)>)\" is a sequence, while substructure \"type=DType str=<dtype: 'int32'>\" is not\nEntire first structure:\n.\nEntire second structure:\nUniqueWithCounts(y=., idx=., count=.)"
     ]
    }
   ],
   "source": [
    "tf.map_fn(lambda t: tf.unique_with_counts(t), tf.stack([label, prediction]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 9), dtype=int32, numpy=\n",
       "array([[1, 2, 3, 2, 3, 3, 1, 2, 2],\n",
       "       [2, 2, 1, 2, 1, 3, 2, 3, 2]], dtype=int32)>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# zip two sequences/tensors\n",
    "tf.stack([label, prediction], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(tp, fp, fn):\n",
    "    precision = tp / (tp + fp) if tp + fp > 0 else 0\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else 0\n",
    "    f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "    return f1, precision, recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         1.         1.        ]\n",
      " [0.88888889 0.8        1.        ]\n",
      " [0.8        1.         0.66666667]]\n",
      "0.8962962962962964 0.9333333333333332 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "all_keys = list(set(tp.keys()).union(set(fp.keys())).union(set(fn.keys())))\n",
    "\n",
    "def compute_metrics_for_class(class_id):\n",
    "    return np.array(compute_metrics(tp[class_id], fp[class_id], fn[class_id]))\n",
    "\n",
    "# for class_id in all_keys:\n",
    "#     tp_ = tp[class_id] if class_id in tp else 0\n",
    "#     fp_ = fp[class_id] if class_id in fp else 0\n",
    "#     fn_ = fn[class_id] if class_id in fn else 0\n",
    "#     print(np.array(compute_metrics(tp_, fp_, fn_)))\n",
    "\n",
    "metrics_per_class = np.asarray(list(map(compute_metrics_for_class, np.array(all_keys))))\n",
    "\n",
    "print(metrics_per_class)\n",
    "\n",
    "f1, precision, recall = np.mean(metrics_per_class, axis = 0)\n",
    "\n",
    "print(f1, precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'true_positives': 2, 'false_positives': 2, 'false_negatives': 1}\n",
      "{'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}\n"
     ]
    }
   ],
   "source": [
    "def compute_confusion_matrix(\n",
    "    y_true, # a vector of token_ids\n",
    "    y_pred # a vector of token_ids\n",
    "):\n",
    "    target_counts = Counter(y_true)\n",
    "    predicted_counts = Counter(y_pred)\n",
    "    \n",
    "    # hits: count all tokens both inside 'predicted' and 'target'\n",
    "    true_positives = sum((target_counts & predicted_counts).values())\n",
    "\n",
    "    # false alarms: count all tokens inside 'predicted', but missing in 'target'\n",
    "    false_positives = sum((predicted_counts - target_counts).values())\n",
    "\n",
    "    # misses: count all tokens inside 'target', but missing in 'predicted'\n",
    "    false_negatives = sum((target_counts - predicted_counts).values())\n",
    "\n",
    "\n",
    "    return {\n",
    "        'true_positives': true_positives,\n",
    "        'false_positives': false_positives,\n",
    "        'false_negatives': false_negatives,\n",
    "    }\n",
    "\n",
    "cm = compute_confusion_matrix(\n",
    "    y_true = ['transform', 'Search', 'Response'],\n",
    "    y_pred = ['modify', 'Search', 'Response', 'Data'],\n",
    "#     y_true = label,\n",
    "#     y_pred = prediction,\n",
    ")\n",
    "\n",
    "precision = cm['true_positives'] / (cm['true_positives'] + cm['false_positives'])\n",
    "recall = cm['true_positives'] / (cm['true_positives'] + cm['false_negatives'])\n",
    "f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "print(cm)\n",
    "print({ 'precision': precision, 'recall': recall, 'f1': f1 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.5, 'recall': 0.6666666666666666, 'f1': 0.5714285714285715}"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_metrics(\n",
    "    y_true, # a vector of token_ids\n",
    "    y_pred # a vector of token_ids\n",
    "):\n",
    "    overlapping = Counter(y_true) & Counter(y_pred)\n",
    "    overlapping_count = sum(overlapping.values())\n",
    "    \n",
    "    precision = 1.0 * overlapping_count / len(y_pred)\n",
    "    recall = 1.0 * overlapping_count / len(y_true)\n",
    "    f1 = (2.0 * precision * recall) / (precision + recall)\n",
    "\n",
    "    return { 'precision': precision, 'recall': recall, 'f1': f1 }\n",
    "\n",
    "compute_metrics(\n",
    "    y_true = ['transform', 'Search', 'Response'],\n",
    "    y_pred = ['modify', 'Search', 'Response', 'Data'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 1.0, 'recall': 1.0, 'f1': 1.0}"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\n",
    "    y_true = [1, 2, 3, 4],\n",
    "    y_pred = [4, 3, 2, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'precision': 0.25, 'recall': 0.3333333333333333, 'f1': 0.28571428571428575}"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_metrics(\n",
    "    y_true = [1, 0, 0],\n",
    "    y_pred = [4, 3, 2, 1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([56], dtype=int32)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tf.constant([34, 56, 12])\n",
    "b = tf.constant([56])\n",
    "intersection = tf.sets.intersection(a[None,:],b[None,:])\n",
    "# tf.sparse_tensor_to_dense(intersection)\n",
    "\n",
    "intersection.values.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5], dtype=int32)>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.sets.intersection(y_true[None,0],y_pred[None,0]).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../data/interim/preprocessed/sequences.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       " array([[1, 2, 3, 4, 5, 0, 0, 0],\n",
       "        [4, 3, 2, 1, 0, 0, 0, 0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(2, 8), dtype=int32, numpy=\n",
       " array([[1, 2, 5, 3, 4, 0, 0, 0],\n",
       "        [4, 2, 2, 1, 0, 0, 0, 0]], dtype=int32)>)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = tf.constant(\n",
    "    [[1, 2, 3, 4, 5, 0, 0, 0],\n",
    "     [4, 3, 2, 1, 0, 0, 0, 0]],\n",
    "    dtype=tf.int32\n",
    ")\n",
    "\n",
    "y_pred = tf.constant(\n",
    "    [[1, 2, 5, 3, 4, 0, 0, 0],\n",
    "     [4, 2, 2, 1, 0, 0, 0, 0]],\n",
    "    dtype=tf.int32\n",
    ")\n",
    "\n",
    "(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'true_positives': 8, 'false_positives': 0, 'false_negatives': 0}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_confusion_matrix(\n",
    "    y_true=y_true[0].numpy(),\n",
    "    y_pred=y_pred[0].numpy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1, 2, 3, 4, 5], [4, 3, 2, 1]]>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove padding\n",
    "y_true_ragged = tf.RaggedTensor.from_tensor(y_true, padding=0)\n",
    "y_true_ragged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[1, 2, 5, 3, 4], [4, 2, 2, 1]]>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pick from y_pred only these items which the y_true decides to pick\n",
    "y_pred_ragged = tf.ragged.boolean_mask(y_pred, tf.cast(y_true, dtype=tf.bool))\n",
    "y_pred_ragged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.4>"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall = tf.keras.metrics.Recall()\n",
    "recall.update_state(\n",
    "    y_true=tf.one_hot(y_true_ragged.to_tensor(), depth=10, axis=-1)[0],\n",
    "    y_pred=tf.one_hot(y_pred_ragged.to_tensor(), depth=10, axis=-1)[0],\n",
    ")\n",
    "recall.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.4>"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = tf.keras.metrics.Precision()\n",
    "\n",
    "precision.update_state(\n",
    "    y_true=tf.one_hot(y_true_ragged.to_tensor(), depth=10, axis=-1)[0],\n",
    "    y_pred=tf.one_hot(y_pred_ragged.to_tensor(), depth=10, axis=-1)[0],\n",
    ")\n",
    "\n",
    "precision.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.88>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = tf.keras.metrics.Accuracy()\n",
    "\n",
    "accuracy.update_state(\n",
    "    y_true=tf.one_hot(y_true_ragged.to_tensor(), depth=10, axis=-1)[0],\n",
    "    y_pred=tf.one_hot(y_pred_ragged.to_tensor(), depth=10, axis=-1)[0],\n",
    ")\n",
    "\n",
    "accuracy.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7, 10), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(y_true, depth=10, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a bool tensor [Op:Mul] name: mul/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-f5126cc610f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_true\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    900\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 902\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    903\u001b[0m       \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1199\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1200\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1202\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1203\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Case: Dense * Sparse.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   6120\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6121\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6122\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6123\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6124\u001b[0m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: cannot compute Mul as input #1(zero-based) was expected to be a int64 tensor but is a bool tensor [Op:Mul] name: mul/"
     ]
    }
   ],
   "source": [
    "y_true * (y_true != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = [\n",
    "    [0.9, 0.1, 0],\n",
    "    [0.2, 0.6, 0.2],\n",
    "    [0, 0, 1],\n",
    "    [0.4, 0.3, 0.3],\n",
    "    [0, 0.9, 0.1],\n",
    "    [0, 0, 1],\n",
    "]\n",
    "actuals = [[1, 0, 0], [0, 1, 0], [0, 0, 1], [1, 0, 0], [1, 0, 0], [0, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision = tf.metrics.Precision()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is there a way to replace tf.one_hot with sparse_tensor? why hasn't anyone though of producing a SparseTensor when using tf.one_hot\n",
    "# however, even if you pass a sparse tensor to update_state, it isn't smart enough yet to accept it\n",
    "# TODO: can we ignore the matching zeros? they are most probably ignore in research papers\n",
    "precision.update_state(\n",
    "    y_pred=tf.one_hot(y_pred, depth=10, axis=-1), # preds\n",
    "    y_true=tf.one_hot(y_true, depth=10, axis=-1)# actuals\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78571427"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SparseTensor' object has no attribute 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-56632301dcc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SparseTensor' object has no attribute 'numpy'"
     ]
    }
   ],
   "source": [
    "tf.sets.intersection(y_true, y_pred).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 7, 256), dtype=float32, numpy=\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]]], dtype=float32)>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.one_hot(y_true, 256, axis = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = tfa.metrics.F1Score(\n",
    "    num_classes=6000,\n",
    "    average=None, # TODO: can be also 'micro', 'macro' or 'weighted'\n",
    "    # Elements of y_pred above threshold are considered to be 1, and the rest 0.\n",
    "    # If threshold is None, the argmax is converted to 1, and the rest 0.\n",
    "    threshold=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in converted code:\n\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_addons/metrics/f_scores.py:141 update_state  *\n        self.true_positives.assign_add(_count_non_zero(y_pred * y_true))\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:786 assign_add\n        name=name)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py:56 assign_add_variable_op\n        \"AssignAddVariableOp\", resource=resource, value=value, name=name)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 0 in both shapes must be equal, but are 6000 and 7. Shapes are [6000] and [7]. for 'AssignAddVariableOp' (op: 'AssignAddVariableOp') with input shapes: [], [7].\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6ab799104a34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m metric.update_state(\n\u001b[1;32m      2\u001b[0m     \u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m )\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/keras/utils/metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# update_op will be None in eager execution.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    614\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 615\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    616\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    495\u001b[0m     self._concrete_stateful_fn = (\n\u001b[1;32m    496\u001b[0m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0;32m--> 497\u001b[0;31m             *args, **kwds))\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minvalid_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0munused_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0munused_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2387\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2388\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2389\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2390\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2391\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2702\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2703\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2704\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2705\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2591\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2592\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2593\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   2594\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2595\u001b[0m         \u001b[0;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    976\u001b[0m                                           converted_func)\n\u001b[1;32m    977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    966\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    969\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in converted code:\n\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_addons/metrics/f_scores.py:141 update_state  *\n        self.true_positives.assign_add(_count_non_zero(y_pred * y_true))\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:786 assign_add\n        name=name)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_resource_variable_ops.py:56 assign_add_variable_op\n        \"AssignAddVariableOp\", resource=resource, value=value, name=name)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/op_def_library.py:742 _apply_op_helper\n        attrs=attr_protos, op_def=op_def)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/func_graph.py:595 _create_op_internal\n        compute_device)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:3322 _create_op_internal\n        op_def=op_def)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1786 __init__\n        control_input_ops)\n    /home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py:1622 _create_c_op\n        raise ValueError(str(e))\n\n    ValueError: Dimension 0 in both shapes must be equal, but are 6000 and 7. Shapes are [6000] and [7]. for 'AssignAddVariableOp' (op: 'AssignAddVariableOp') with input shapes: [], [7].\n"
     ]
    }
   ],
   "source": [
    "metric.update_state(\n",
    "    y_true=y_true,\n",
    "    y_pred=y_pred,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   8,   15,  486,   10,    7,    5,  137, 4043,    4,  140,    3,\n",
       "        1674,  259,   48,   25,    4,   58,    2,    5,  137, 4043,    4,\n",
       "         140,  132,    3,    7,   17,  486,    2,    5, 1144,  609, 2062,\n",
       "           3,  486,    2,    5,    9,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0],\n",
       "       [   8,   13,   42,    3,    7,    6, 1144,  609, 2062,    3,    7,\n",
       "           2,    2,    5,    9,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0]])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(df['inputs'].head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(l):\n",
    "    return [item for sublist in l for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifiers = ['public', 'private', 'protected', 'static']\n",
    "\n",
    "RE_WORDS = re.compile(r'''\n",
    "    # Find words in a string. Order matters!\n",
    "    [A-Z]+(?=[A-Z][a-z]) |  # All upper case before a capitalized word\n",
    "    [A-Z]?[a-z]+ |  # Capitalized words / all lower case\n",
    "    [A-Z]+ |  # All upper case\n",
    "    \\d+ | # Numbers\n",
    "    .+\n",
    "''', re.VERBOSE)\n",
    "\n",
    "def split_subtokens(str):\n",
    "    return [subtok for subtok in RE_WORDS.findall(str) if not subtok == '_']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_method(method_body):\n",
    "    method_content = method_body\n",
    "    try:\n",
    "        tokens = list(javalang.tokenizer.tokenize(method_content))\n",
    "    except:\n",
    "        print('ERROR in tokenizing: ' + method_content)\n",
    "        #tokens = method_content.split(' ')\n",
    "    if len(tokens) > 0:\n",
    "        return ' '.join([' '.join(split_subtokens(i.value)) for i in tokens if not i.value in modifiers])\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'void ( String foo Bar ) { System . out . println ( \"hello world\" ) ; }'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_method('void (String fooBar){System.out.println(\"hello world\");}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "    num_words=1000,\n",
    "    filters='',\n",
    "    lower=False,\n",
    "    oov_token='<OOV>',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    ['{', 'printf', '(', '\"', 'hello', 'world', '\"', ')', ';', '}'],\n",
    "    ['{', 'fprintf', '(', '\"', 'hello', 'dad', '\"', ')', ';', '}'],\n",
    "    ['{', 'vprintf', '(', '\"', 'hello', 'mom', '\"', ')', ';', '}'],\n",
    "]\n",
    "\n",
    "texts = [\n",
    "    'void ( String foo Bar ) { System . out . println ( \" hello world \" ) ; }'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(chain.from_iterable(sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.num_words = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<OOV>': 1,\n",
       " '\"': 2,\n",
       " '{': 3,\n",
       " '(': 4,\n",
       " 'hello': 5,\n",
       " ')': 6,\n",
       " ';': 7,\n",
       " '}': 8,\n",
       " 'printf': 9,\n",
       " 'world': 10,\n",
       " 'fprintf': 11,\n",
       " 'dad': 12,\n",
       " 'vprintf': 13,\n",
       " 'mom': 14}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['{', 'printf', '(', '\"', 'hello', 'world', '\"', ')', ';', '}']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(map(lambda l: flatten(l), sequences))\n",
    "sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3, 9, 4, 2, 5, 10, 2, 6, 7, 8],\n",
       " [3, 11, 4, 2, 5, 12, 2, 6, 7, 8],\n",
       " [3, 13, 4, 2, 5, 14, 2, 6, 7, 8]]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.texts_to_sequences(map(lambda l: ' '.join(l), sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_hdf('../data/interim/preprocessed/sequences.h5', key='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorSliceDataset shapes: (200,), types: tf.int64>"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(np.stack(df['inputs'].values))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(200,), dtype=int64, numpy=\n",
       "array([61674, 16275, 29012, 40249, 25223,  6673, 15050, 59831, 11591,\n",
       "       14256, 15050, 39792, 68638, 25223,  6673, 15050, 32537, 11591,\n",
       "       40249, 33282, 16275, 68638, 25223, 60298, 11591, 16275, 68638,\n",
       "       25223, 32001, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100, 53100,\n",
       "       53100, 53100])>"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifted = next(iter(dataset.map(lambda seq: seq[1:])))\n",
    "tf.concat(axis=0, values=[shifted, [53100]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([512, 256])>"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "tf.concat(values=[tf.constant(np.array([512])), [256]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4]"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1, 2, 3, 4, 5][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = [\n",
    "    'We pad the sequece in the post-order where maxlen is max_seq_length.',\n",
    "    'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.string>\n",
      "\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<TensorSliceDataset shapes: (), types: tf.string>\n",
      "\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "[8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "<- encoded_text after py_function: Tensor(\"encode:0\", dtype=int64)\n",
      "<MapDataset shapes: <unknown>, types: tf.int64>\n",
      "\n",
      "---> b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "<--- [8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[ 8  6 15  2  7 15 19  1 14 17 12  4]\n",
      "---> b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "<--- [20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[20 11 10 12  9 21  4 16 22 15 19  5 13 18  3]\n",
      "---> b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "<--- [8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[ 8  6 15  2  7 15 19  1 14 17 12  4]\n",
      "---> b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "<--- [20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[20 11 10 12  9 21  4 16 22 15 19  5 13 18  3]\n",
      "---> b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "<--- [8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[ 8  6 15  2  7 15 19  1 14 17 12  4]\n",
      "<MapDataset shapes: <unknown>, types: tf.float32>\n",
      "\n",
      "---> b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "<--- [8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "---> b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "<--- [20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "---> b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "<--- [8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "---> b'If any vector is larger than max_seq_length, we truncate the post-sequence to shorten it.'\n",
      "<--- [20, 11, 10, 12, 9, 21, 4, 16, 22, 15, 19, 5, 13, 18, 3]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "---> b'We pad the sequece in the post-order where maxlen is max_seq_length.'\n",
      "<--- [8, 6, 15, 2, 7, 15, 19, 1, 14, 17, 12, 4]\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# 1. create Dataset entity\n",
    "dataset = tf.data.Dataset.from_tensor_slices(sentences * 10)\n",
    "\n",
    "print(dataset)\n",
    "print()\n",
    "for item in dataset:\n",
    "    print(item.numpy())\n",
    "\n",
    "# 2. Tokenize\n",
    "# 3. Build vocabulary\n",
    "\n",
    "# TODO: swap out the tokenizer with the javalang tokenizer\n",
    "tokenizer = tfds.features.text.Tokenizer()\n",
    "\n",
    "vocabulary_set = set()\n",
    "for text_tensor in dataset.take(2):\n",
    "    some_tokens = tokenizer.tokenize(text_tensor.numpy())\n",
    "    vocabulary_set.update(some_tokens)\n",
    "\n",
    "vocab_size = len(vocabulary_set)\n",
    "vocab_size\n",
    "\n",
    "# 4. Encode the text/tokens into numbers\n",
    "\n",
    "# TODO: this is very bad design by TF, because it includes both tokenization AND encoding\n",
    "# we already did the tokenization in the last step ...\n",
    "encoder = tfds.features.text.TokenTextEncoder(vocabulary_set)\n",
    "\n",
    "example_text = next(iter(dataset)).numpy()\n",
    "print(example_text)\n",
    "encoded_example = encoder.encode(example_text)\n",
    "print(encoded_example)\n",
    "\n",
    "for text_tensor in dataset.take(10):\n",
    "    print(encoder.encode(text_tensor.numpy()))\n",
    "\n",
    "def encode(text_tensor):\n",
    "    print('--->', text_tensor.numpy())\n",
    "    encoded_text = encoder.encode(text_tensor.numpy())\n",
    "    print('<---', encoded_text)\n",
    "    \n",
    "    # TODO: why the fuck do we need to return a fucking list/tuple here?\n",
    "    return [encoded_text]\n",
    "\n",
    "def encode_map_fn(text):\n",
    "    # py_func doesn't set the shape of the returned tensors.\n",
    "    # TODO: but why?!?\n",
    "    encoded_text = tf.py_function(encode, inp=[text], Tout=tf.int64, name='encode')\n",
    "    \n",
    "    print(f'<- encoded_text after py_function: {encoded_text}')\n",
    "    \n",
    "    # `tf.data.Datasets` work best if all components have a shape set\n",
    "    #  so set the shapes manually: \n",
    "    # TODO: but why?!?\n",
    "#     encoded_text.set_shape([None])\n",
    "\n",
    "    return encoded_text\n",
    "\n",
    "dataset = dataset.map(encode_map_fn)\n",
    "\n",
    "print(dataset)\n",
    "print()\n",
    "for item in dataset.take(5):\n",
    "    print(item.numpy())\n",
    "\n",
    "# # 5. pad sequences\n",
    "# def pad_seq(seq):\n",
    "#     \"\"\"\n",
    "#         We pad the sequece in the post-order where maxlen is max_seq_length.\n",
    "#         If any vector is larger than max_seq_length, we truncate the post-sequence\n",
    "#     \"\"\"\n",
    "#     return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "#         [seq], # TODO: [seq.numpy()]?\n",
    "#         maxlen=max_seq_length,\n",
    "#         truncating='post',\n",
    "#         padding='post',\n",
    "#         value='',\n",
    "# #         dtype=np.float\n",
    "#     ).squeeze() # TODO: why sequeeze?\n",
    "\n",
    "# # def pad_map_fn(seq):\n",
    "# #     return tf.py_function(pad_seq, inp=[seq], Tout=(tf.float32))\n",
    "# def pad_seq_map_fn(seq):\n",
    "#     seq.numpy()\n",
    "\n",
    "# dataset = dataset.map(pad_seq_map_fn)\n",
    "    \n",
    "# 6. one-hot encode\n",
    "dataset = dataset.map(lambda seq: tf.one_hot(seq, vocab_size))\n",
    "\n",
    "\n",
    "print(dataset)\n",
    "print()\n",
    "for item in dataset.take(5):\n",
    "    print(item.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "label1 = ['transform', 'Search', 'Response']\n",
    "label2 = ['get', 'Abstract', 'Factory', 'Creator', 'Service']\n",
    "labels = [label1, label2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_seq(seq):\n",
    "    \"\"\"\n",
    "        We pad the sequece in the post-order where maxlen is max_seq_length.\n",
    "        If any vector is larger than max_seq_length, we truncate the post-sequence\n",
    "    \"\"\"\n",
    "    return tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [seq], # TODO: [seq.numpy()]?\n",
    "        maxlen=max_seq_length,\n",
    "        truncating='post',\n",
    "        padding='post',\n",
    "        value='',\n",
    "#         dtype=np.float\n",
    "    ).squeeze() # TODO: why sequeeze?\n",
    "\n",
    "# def pad_map_fn(seq):\n",
    "#     return tf.py_function(pad_seq, inp=[seq], Tout=(tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'transform', b'Search', b'Response'], [b'get', b'Abstract', b'Factory', b'Creator', b'Service']]>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tensor = tf.ragged.constant(labels)\n",
    "labels_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Service': 0,\n",
       " 'get': 1,\n",
       " 'Response': 2,\n",
       " 'Creator': 3,\n",
       " 'transform': 4,\n",
       " 'Abstract': 5,\n",
       " 'Factory': 6,\n",
       " 'Search': 7}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_vocabulary = {token for label in labels for token in label}\n",
    "label_vocabulary\n",
    "\n",
    "label_to_index = { index: token for token, index in enumerate(label_vocabulary) }\n",
    "label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 5), dtype=string, numpy=\n",
       "array([[b'transform', b'Search', b'Response', b'', b''],\n",
       "       [b'get', b'Abstract', b'Factory', b'Creator', b'Service']],\n",
       "      dtype=object)>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_tensor.to_tensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`dtype` int32 is not compatible with `value`'s type: <class 'str'>\nYou should set `dtype=object` for variable length strings.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b765c471e63a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# 2. From RaggedTensors to normal Tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpad_seq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-6643ddfbd70d>\u001b[0m in \u001b[0;36mpad_seq\u001b[0;34m(seq)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtruncating\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'post'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;31m#         dtype=np.float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     ).squeeze() # TODO: why sequeeze?\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/keras_preprocessing/sequence.py\u001b[0m in \u001b[0;36mpad_sequences\u001b[0;34m(sequences, maxlen, dtype, padding, truncating, value)\u001b[0m\n\u001b[1;32m     79\u001b[0m         raise ValueError(\"`dtype` {} is not compatible with `value`'s type: {}\\n\"\n\u001b[1;32m     80\u001b[0m                          \u001b[0;34m\"You should set `dtype=object` for variable length strings.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m                          .format(dtype, type(value)))\n\u001b[0m\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: `dtype` int32 is not compatible with `value`'s type: <class 'str'>\nYou should set `dtype=object` for variable length strings."
     ]
    }
   ],
   "source": [
    "# 2. From RaggedTensors to normal Tensors\n",
    "pad_seq(labels_tensor.to_tensor().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\nTraceback (most recent call last):\n\n  File \"/home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 234, in __call__\n    return func(device, token, args)\n\n  File \"/home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 123, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-37-7853e3c76557>\", line 4, in <lambda>\n    tf.py_function(lambda token: label_to_index[token], [labels_tensor.to_tensor()], tf.int64)\n\n  File \"/home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 705, in __hash__\n    raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\n\nTypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\n\n [Op:EagerPyFunc]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-7853e3c76557>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# ValueError: TypeError: object of type 'RaggedTensor' has no len()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# tf.map_fn(lambda token: label_to_index[token], labels_tensor.to_tensor())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlabel_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlabels_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[0;34m(func, inp, Tout, name)\u001b[0m\n\u001b[1;32m    426\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m   \"\"\"\n\u001b[0;32m--> 428\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_internal_py_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\u001b[0m in \u001b[0;36m_internal_py_func\u001b[0;34m(func, inp, Tout, stateful, eager, is_grad_func, name)\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0mis_async\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0mTout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 317\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m    318\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_script_ops.py\u001b[0m in \u001b[0;36meager_py_func\u001b[0;34m(input, token, Tout, is_async, name)\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"token\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: TypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\nTraceback (most recent call last):\n\n  File \"/home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 234, in __call__\n    return func(device, token, args)\n\n  File \"/home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/script_ops.py\", line 123, in __call__\n    ret = self._func(*args)\n\n  File \"<ipython-input-37-7853e3c76557>\", line 4, in <lambda>\n    tf.py_function(lambda token: label_to_index[token], [labels_tensor.to_tensor()], tf.int64)\n\n  File \"/home/tony/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\", line 705, in __hash__\n    raise TypeError(\"Tensor is unhashable if Tensor equality is enabled. \"\n\nTypeError: Tensor is unhashable if Tensor equality is enabled. Instead, use tensor.experimental_ref() as the key.\n\n [Op:EagerPyFunc]"
     ]
    }
   ],
   "source": [
    "\n",
    "# first you have to convert the RaggedTensor to a normal tensor\n",
    "# ValueError: TypeError: object of type 'RaggedTensor' has no len()\n",
    "# tf.map_fn(lambda token: label_to_index[token], labels_tensor.to_tensor())\n",
    "tf.py_function(lambda token: label_to_index[token], [labels_tensor.to_tensor()], tf.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='XLA_CPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_CPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_GPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='XLA_GPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n [Op:OneHot] name: RaggedOneHot/one_hot/",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-ec106b544667>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mone_hot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_vocabulary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m       \u001b[0;31m# TypeError, when given unexpected types.  So we need to catch both.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mdispatch\u001b[0;34m(op, *args, **kwargs)\u001b[0m\n\u001b[1;32m     99\u001b[0m   \"\"\"\n\u001b[1;32m    100\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mdispatcher\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDISPATCH_ATTR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/ragged/ragged_dispatch.py\u001b[0m in \u001b[0;36mhandle\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_supported\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ragged_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/ragged/ragged_array_ops.py\u001b[0m in \u001b[0;36mragged_one_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m    539\u001b[0m     return indices.with_flat_values(\n\u001b[1;32m    540\u001b[0m         array_ops.one_hot(indices.flat_values, depth, on_value, off_value, axis,\n\u001b[0;32m--> 541\u001b[0;31m                           dtype, name))\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, dtype, name)\u001b[0m\n\u001b[1;32m   3643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3644\u001b[0m     return gen_array_ops.one_hot(indices, depth, on_value, off_value, axis,\n\u001b[0;32m-> 3645\u001b[0;31m                                  name)\n\u001b[0m\u001b[1;32m   3646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3647\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36mone_hot\u001b[0;34m(indices, depth, on_value, off_value, axis, name)\u001b[0m\n\u001b[1;32m   5547\u001b[0m         \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5548\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5549\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5550\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5551\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6604\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6605\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6606\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6607\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6608\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/source/identifier-suggestion/.venv/lib/python3.7/site-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Could not find valid device for node.\nNode:{{node OneHot}}\nAll kernels registered for op OneHot :\n  device='XLA_CPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_CPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='XLA_GPU_JIT'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_VARIANT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_RESOURCE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT32]; T in [DT_STRING]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_STRING]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX128]\n  device='CPU'; TI in [DT_INT64]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_COMPLEX64]\n  device='CPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='CPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='CPU'; TI in [DT_INT64]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_BFLOAT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT8]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT32]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_UINT16]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='CPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='CPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='CPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT64]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT64]\n  device='GPU'; TI in [DT_INT64]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT32]; T in [DT_INT32]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_INT32]\n  device='GPU'; TI in [DT_INT64]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT32]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_BOOL]\n  device='GPU'; TI in [DT_INT64]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT32]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_DOUBLE]\n  device='GPU'; TI in [DT_INT64]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT32]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_FLOAT]\n  device='GPU'; TI in [DT_INT64]; T in [DT_HALF]\n  device='GPU'; TI in [DT_INT32]; T in [DT_HALF]\n  device='GPU'; TI in [DT_UINT8]; T in [DT_HALF]\n  device='XLA_GPU'; TI in [DT_INT32, DT_UINT8, DT_INT64]; T in [DT_FLOAT, DT_DOUBLE, DT_INT32, DT_UINT8, DT_INT16, ..., DT_UINT16, DT_COMPLEX128, DT_HALF, DT_UINT32, DT_UINT64]\n [Op:OneHot] name: RaggedOneHot/one_hot/"
     ]
    }
   ],
   "source": [
    "tf.one_hot(labels_tensor, len(label_vocabulary))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
